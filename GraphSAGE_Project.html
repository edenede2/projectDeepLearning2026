<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>GraphSAGE_Project</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iLTEwIC0xMCAxMzEuMTYxMzYxNjk0MzM1OTQgMTMyLjM4ODk5OTkzODk2NDg0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzA2OTk4IiBkPSJNIDU0LjkxODc4NSw5LjE5Mjc0MjFlLTQgQyA1MC4zMzUxMzIsMC4wMjIyMTcyNyA0NS45NTc4NDYsMC40MTMxMzY5NyA0Mi4xMDYyODUsMS4wOTQ2NjkzIDMwLjc2MDA2OSwzLjA5OTE3MzEgMjguNzAwMDM2LDcuMjk0NzcxNCAyOC43MDAwMzUsMTUuMDMyMTY5IHYgMTAuMjE4NzUgaCAyNi44MTI1IHYgMy40MDYyNSBoIC0yNi44MTI1IC0xMC4wNjI1IGMgLTcuNzkyNDU5LDAgLTE0LjYxNTc1ODgsNC42ODM3MTcgLTE2Ljc0OTk5OTgsMTMuNTkzNzUgLTIuNDYxODE5OTgsMTAuMjEyOTY2IC0yLjU3MTAxNTA4LDE2LjU4NjAyMyAwLDI3LjI1IDEuOTA1OTI4Myw3LjkzNzg1MiA2LjQ1NzU0MzIsMTMuNTkzNzQ4IDE0LjI0OTk5OTgsMTMuNTkzNzUgaCA5LjIxODc1IHYgLTEyLjI1IGMgMCwtOC44NDk5MDIgNy42NTcxNDQsLTE2LjY1NjI0OCAxNi43NSwtMTYuNjU2MjUgaCAyNi43ODEyNSBjIDcuNDU0OTUxLDAgMTMuNDA2MjUzLC02LjEzODE2NCAxMy40MDYyNSwtMTMuNjI1IHYgLTI1LjUzMTI1IGMgMCwtNy4yNjYzMzg2IC02LjEyOTk4LC0xMi43MjQ3NzcxIC0xMy40MDYyNSwtMTMuOTM3NDk5NyBDIDY0LjI4MTU0OCwwLjMyNzk0Mzk3IDU5LjUwMjQzOCwtMC4wMjAzNzkwMyA1NC45MTg3ODUsOS4xOTI3NDIxZS00IFogbSAtMTQuNSw4LjIxODc1MDEyNTc5IGMgMi43Njk1NDcsMCA1LjAzMTI1LDIuMjk4NjQ1NiA1LjAzMTI1LDUuMTI0OTk5NiAtMmUtNiwyLjgxNjMzNiAtMi4yNjE3MDMsNS4wOTM3NSAtNS4wMzEyNSw1LjA5Mzc1IC0yLjc3OTQ3NiwtMWUtNiAtNS4wMzEyNSwtMi4yNzc0MTUgLTUuMDMxMjUsLTUuMDkzNzUgLTEwZS03LC0yLjgyNjM1MyAyLjI1MTc3NCwtNS4xMjQ5OTk2IDUuMDMxMjUsLTUuMTI0OTk5NiB6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2ZmZDQzYiIgZD0ibSA4NS42Mzc1MzUsMjguNjU3MTY5IHYgMTEuOTA2MjUgYyAwLDkuMjMwNzU1IC03LjgyNTg5NSwxNi45OTk5OTkgLTE2Ljc1LDE3IGggLTI2Ljc4MTI1IGMgLTcuMzM1ODMzLDAgLTEzLjQwNjI0OSw2LjI3ODQ4MyAtMTMuNDA2MjUsMTMuNjI1IHYgMjUuNTMxMjQ3IGMgMCw3LjI2NjM0NCA2LjMxODU4OCwxMS41NDAzMjQgMTMuNDA2MjUsMTMuNjI1MDA0IDguNDg3MzMxLDIuNDk1NjEgMTYuNjI2MjM3LDIuOTQ2NjMgMjYuNzgxMjUsMCA2Ljc1MDE1NSwtMS45NTQzOSAxMy40MDYyNTMsLTUuODg3NjEgMTMuNDA2MjUsLTEzLjYyNTAwNCBWIDg2LjUwMDkxOSBoIC0yNi43ODEyNSB2IC0zLjQwNjI1IGggMjYuNzgxMjUgMTMuNDA2MjU0IGMgNy43OTI0NjEsMCAxMC42OTYyNTEsLTUuNDM1NDA4IDEzLjQwNjI0MSwtMTMuNTkzNzUgMi43OTkzMywtOC4zOTg4ODYgMi42ODAyMiwtMTYuNDc1Nzc2IDAsLTI3LjI1IC0xLjkyNTc4LC03Ljc1NzQ0MSAtNS42MDM4NywtMTMuNTkzNzUgLTEzLjQwNjI0MSwtMTMuNTkzNzUgeiBtIC0xNS4wNjI1LDY0LjY1NjI1IGMgMi43Nzk0NzgsM2UtNiA1LjAzMTI1LDIuMjc3NDE3IDUuMDMxMjUsNS4wOTM3NDcgLTJlLTYsMi44MjYzNTQgLTIuMjUxNzc1LDUuMTI1MDA0IC01LjAzMTI1LDUuMTI1MDA0IC0yLjc2OTU1LDAgLTUuMDMxMjUsLTIuMjk4NjUgLTUuMDMxMjUsLTUuMTI1MDA0IDJlLTYsLTIuODE2MzMgMi4yNjE2OTcsLTUuMDkzNzQ3IDUuMDMxMjUsLTUuMDkzNzQ3IHoiLz4KPC9zdmc+Cg==);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8cb22c41">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="GraphSAGE:-Inductive-Representation-Learning-on-Large-Graphs">GraphSAGE: Inductive Representation Learning on Large Graphs<a class="anchor-link" href="#GraphSAGE:-Inductive-Representation-Learning-on-Large-Graphs"></a></h1><h2 id="Deep-Learning-Final-Project-(Paper-Faithful-Implementation)">Deep Learning Final Project (Paper-Faithful Implementation)<a class="anchor-link" href="#Deep-Learning-Final-Project-(Paper-Faithful-Implementation)"></a></h2><p>This notebook implements the <strong>GraphSAGE</strong> (SAmple and aggreGatE) algorithm from the paper:</p>
<blockquote>
<p><em>"Inductive Representation Learning on Large Graphs"</em> by Hamilton et al. (NIPS 2017)</p>
</blockquote>
<h3 id="Project-Overview">Project Overview<a class="anchor-link" href="#Project-Overview"></a></h3><ul>
<li><strong>Task</strong>: Supervised node classification using GraphSAGE</li>
<li><strong>Datasets</strong>: PPI (Protein-Protein Interaction), Reddit, and Cora</li>
<li><strong>Framework</strong>: PyTorch + PyTorch Geometric</li>
<li><strong>Key Feature</strong>: <strong>Strict inductive training</strong> (no val/test features during training)</li>
</ul>
<h3 id="Key-Implementation-Details">Key Implementation Details<a class="anchor-link" href="#Key-Implementation-Details"></a></h3><ol>
<li><strong>Strict Inductive Protocol</strong>: Train on induced subgraph with only train nodes</li>
<li><strong>Paper-Faithful Model</strong>: Mean aggregator, no BatchNorm</li>
<li><strong>PPI Evaluation</strong>: Per-graph F1 mean (paper-style)</li>
<li><strong>Sanity Checks</strong>: Random label test + overfit test to detect leakage</li>
</ol>
<h3 id="Results-Summary">Results Summary<a class="anchor-link" href="#Results-Summary"></a></h3><table>
<thead>
<tr>
<th>Dataset</th>
<th>Our F1</th>
<th>Paper F1</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cora</td>
<td>44.0%</td>
<td>77.8%</td>
<td>Lower (strict inductive on sparse graph)</td>
</tr>
<tr>
<td>PPI</td>
<td>72.6%</td>
<td>59.8%</td>
<td><strong>Exceeded paper!</strong></td>
</tr>
<tr>
<td>Reddit</td>
<td>93.6%</td>
<td>95.0%</td>
<td>Close match (-1.4%)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b4fa2459">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="1.-Setup-and-Imports">1. Setup and Imports<a class="anchor-link" href="#1.-Setup-and-Imports"></a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=01005643">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Core libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>

<span class="c1"># PyTorch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>

<span class="c1"># Device configuration - works on both CPU and GPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">'cuda'</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"GPU: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Memory: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CPU cores available: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cpu
CPU cores available: 32
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=14be91c7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># PyTorch Geometric - for graph neural networks</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPI</span><span class="p">,</span> <span class="n">Reddit</span><span class="p">,</span> <span class="n">Planetoid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.loader</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">NeighborLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">SAGEConv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Data</span>

<span class="c1"># Import pyg-lib for efficient neighbor sampling (required for NeighborLoader)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pyg_lib</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"pyg-lib version: </span><span class="si">{</span><span class="n">pyg_lib</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"pyg-lib not available - NeighborLoader may not work"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"PyTorch Geometric imported successfully!"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>pyg-lib version: 0.6.0.dev20260104+pt29cu128
PyTorch Geometric imported successfully!
PyTorch version: 2.9.1+cu128
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8830a042">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="2.-Configuration">2. Configuration<a class="anchor-link" href="#2.-Configuration"></a></h2><p>Set up hyperparameters and paths. These can be adjusted for experimentation.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=c756adae">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Configuration dictionary for easy experimentation</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Data paths</span>
    <span class="s1">'data_root'</span><span class="p">:</span> <span class="s1">'./data'</span><span class="p">,</span>
    
    <span class="c1"># GraphSAGE architecture (as per paper: K=2 layers)</span>
    <span class="s1">'num_layers'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">'hidden_dim'</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    
    <span class="c1"># Neighborhood sampling (paper: S1=25, S2=10)</span>
    <span class="s1">'num_neighbors'</span><span class="p">:</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    
    <span class="c1"># Training parameters</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s1">'weight_decay'</span><span class="p">:</span> <span class="mf">5e-4</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
    
    <span class="c1"># Reproducibility</span>
    <span class="s1">'seed'</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
    
    <span class="c1"># Paper-faithful settings</span>
    <span class="s1">'use_batchnorm'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># Paper did NOT use BatchNorm; toggle for ablation</span>
    <span class="s1">'aggregator'</span><span class="p">:</span> <span class="s1">'mean'</span><span class="p">,</span>    <span class="c1"># Options: 'mean', 'gcn', 'pool'</span>
<span class="p">}</span>

<span class="c1"># Paper-like hyperparameter config for faithful reproduction</span>
<span class="n">paper_like_cfg</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'K'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>                        <span class="c1"># Number of GNN layers</span>
    <span class="s1">'hidden_dim'</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>             <span class="c1"># Hidden dimension for PPI</span>
    <span class="s1">'S1'</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span> <span class="s1">'S2'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>            <span class="c1"># Neighbor samples per hop</span>
    <span class="s1">'activation'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'dropout'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="s1">'lr_sweep'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span>
    <span class="s1">'wd_sweep'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">],</span>
    <span class="s1">'aggregators'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'gcn'</span><span class="p">,</span> <span class="s1">'pool'</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># Set seeds for reproducibility</span>
<span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Configuration loaded and seeds set."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"BatchNorm: </span><span class="si">{</span><span class="s1">'ON'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">'OFF (paper-faithful)'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Configuration loaded and seeds set.
BatchNorm: OFF (paper-faithful)
Aggregator: mean
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6e9a9dce">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3.-Load-Datasets">3. Load Datasets<a class="anchor-link" href="#3.-Load-Datasets"></a></h2><p>We'll work with three benchmark datasets from the GraphSAGE paper:</p>
<ol>
<li><strong>Cora</strong> - Citation network (7 classes, ~2.7K nodes)</li>
<li><strong>PPI</strong> - Protein-Protein Interaction graphs (121 labels, multi-label classification)</li>
<li><strong>Reddit</strong> - Social network posts (~233K nodes, 41 classes)</li>
</ol>
<h3 id="Important:-Data-Leakage-Considerations-in-GNNs">Important: Data Leakage Considerations in GNNs<a class="anchor-link" href="#Important:-Data-Leakage-Considerations-in-GNNs"></a></h3><p><strong>Transductive vs Inductive Learning:</strong></p>
<ul>
<li><strong>Cora &amp; Reddit</strong>: Use <strong>transductive</strong> setting where all node features are visible during training, but only train node <strong>labels</strong> are used for supervision. This follows the standard benchmark protocol.</li>
<li><strong>PPI</strong>: Uses <strong>inductive</strong> setting with completely separate train/val/test graphs - no data leakage possible.</li>
</ul>
<p><strong>Why this is NOT data leakage:</strong></p>
<ol>
<li>During training, we only compute loss on <code>train_mask</code> nodes</li>
<li>Test node <strong>labels</strong> are never seen during training</li>
<li>The model learns to aggregate neighborhood features, not memorize labels</li>
<li>This is the standard evaluation protocol used in the original GraphSAGE paper</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=32b42a4a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Load Cora dataset (smallest - good for quick testing)</span>
<span class="n">cora_dataset</span> <span class="o">=</span> <span class="n">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'data_root'</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'Cora'</span><span class="p">)</span>
<span class="n">cora_data</span> <span class="o">=</span> <span class="n">cora_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"CORA DATASET"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cora_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of nodes: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of edges: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of features: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">num_node_features</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of classes: </span><span class="si">{</span><span class="n">cora_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Has isolated nodes: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">has_isolated_nodes</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Is undirected: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">is_undirected</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Train/Val/Test split:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train nodes: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Val nodes: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test nodes: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================
CORA DATASET
==================================================
Number of graphs: 1
Number of nodes: 2708
Number of edges: 10556
Number of features: 1433
Number of classes: 7
Has isolated nodes: False
Is undirected: True

Train/Val/Test split:
  Train nodes: 140
  Val nodes: 500
  Test nodes: 1000
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=090c50ff">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Load PPI dataset (multi-graph, multi-label classification)</span>
<span class="n">ppi_train</span> <span class="o">=</span> <span class="n">PPI</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'data_root'</span><span class="p">]</span><span class="si">}</span><span class="s2">/PPI"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">'train'</span><span class="p">)</span>
<span class="n">ppi_val</span> <span class="o">=</span> <span class="n">PPI</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'data_root'</span><span class="p">]</span><span class="si">}</span><span class="s2">/PPI"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">'val'</span><span class="p">)</span>
<span class="n">ppi_test</span> <span class="o">=</span> <span class="n">PPI</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'data_root'</span><span class="p">]</span><span class="si">}</span><span class="s2">/PPI"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">'test'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"PPI DATASET (Protein-Protein Interaction)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Train graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_train</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Val graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_val</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Sample train graph stats:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Nodes: </span><span class="si">{</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Edges: </span><span class="si">{</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Features: </span><span class="si">{</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_node_features</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Labels (multi-label): </span><span class="si">{</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================
PPI DATASET (Protein-Protein Interaction)
==================================================
Train graphs: 20
Val graphs: 2
Test graphs: 2

Sample train graph stats:
  Nodes: 1767
  Edges: 32318
  Features: 50
  Labels (multi-label): 121
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=8b903325">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Load Reddit dataset (large-scale, may take a moment to download)</span>
<span class="c1"># Note: Reddit is ~1GB, we'll load it but can skip if memory is limited</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">reddit_dataset</span> <span class="o">=</span> <span class="n">Reddit</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'data_root'</span><span class="p">]</span><span class="si">}</span><span class="s2">/Reddit"</span><span class="p">)</span>
    <span class="n">reddit_data</span> <span class="o">=</span> <span class="n">reddit_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"REDDIT DATASET"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of nodes: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of edges: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of features: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_node_features</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of classes: </span><span class="si">{</span><span class="n">reddit_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Train/Val/Test split:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train nodes: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Val nodes: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test nodes: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">REDDIT_AVAILABLE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit dataset loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Continuing without Reddit dataset..."</span><span class="p">)</span>
    <span class="n">REDDIT_AVAILABLE</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>==================================================
REDDIT DATASET
==================================================
Number of nodes: 232965
Number of edges: 114615892
Number of features: 602
Number of classes: 41

Train/Val/Test split:
  Train nodes: 153431
  Val nodes: 23831
  Test nodes: 55703
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fdc47177">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Data-Leakage-Validation">Data Leakage Validation<a class="anchor-link" href="#Data-Leakage-Validation"></a></h3><p>Let's verify that our train/val/test splits are valid and there's no label leakage.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=997e6f78">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">validate_no_data_leakage</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Validate that train/val/test splits are mutually exclusive and proper.</span>
<span class="sd">    """</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"DATA LEAKAGE VALIDATION: </span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="n">train_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_mask</span>
    <span class="n">val_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">val_mask</span>  
    <span class="n">test_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span>
    
    <span class="c1"># Check 1: Masks are mutually exclusive</span>
    <span class="n">train_val_overlap</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_mask</span> <span class="o">&amp;</span> <span class="n">val_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">train_test_overlap</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_mask</span> <span class="o">&amp;</span> <span class="n">test_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">val_test_overlap</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_mask</span> <span class="o">&amp;</span> <span class="n">test_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">1. MUTUAL EXCLUSIVITY CHECK:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Train-Val overlap: </span><span class="si">{</span><span class="n">train_val_overlap</span><span class="si">}</span><span class="s2"> nodes"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Train-Test overlap: </span><span class="si">{</span><span class="n">train_test_overlap</span><span class="si">}</span><span class="s2"> nodes"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Val-Test overlap: </span><span class="si">{</span><span class="n">val_test_overlap</span><span class="si">}</span><span class="s2"> nodes"</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">train_val_overlap</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">train_test_overlap</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">val_test_overlap</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"    PASSED: All splits are mutually exclusive"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"    FAILED: Overlapping nodes detected!"</span><span class="p">)</span>
    
    <span class="c1"># Check 2: Coverage</span>
    <span class="n">total_masked</span> <span class="o">=</span> <span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">2. COVERAGE CHECK:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Total nodes: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Nodes with masks: </span><span class="si">{</span><span class="n">total_masked</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Train: </span><span class="si">{</span><span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">train_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Val: </span><span class="si">{</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Test: </span><span class="si">{</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
    
    <span class="c1"># Check 3: Label distribution (no label leakage check)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">3. LABEL DISTRIBUTION CHECK:"</span><span class="p">)</span>
    <span class="n">train_labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">train_mask</span><span class="p">]</span>
    <span class="n">val_labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">val_mask</span><span class="p">]</span>
    <span class="n">test_labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">test_mask</span><span class="p">]</span>
    
    <span class="n">num_classes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Number of classes: </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Check if all classes are represented in train</span>
    <span class="n">train_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
    <span class="n">val_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">val_labels</span><span class="p">)</span>
    <span class="n">test_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Classes in train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Classes in val: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"   Classes in test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_classes</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_classes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"    All classes represented in training set"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"    Warning: Only </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_classes</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2"> classes in train"</span><span class="p">)</span>
    
    <span class="c1"># Check 4: Transductive setting explanation</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">4. SUPERVISED LEARNING PROTOCOL:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   During training:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   - Node FEATURES (x) of ALL nodes are used for message passing"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   - Node LABELS (y) of ONLY train_mask nodes are used for loss"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   - This is the standard transductive GNN evaluation protocol"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   - Test labels are NEVER seen during training  No label leakage"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="kc">True</span>

<span class="c1"># Validate Cora</span>
<span class="n">validate_no_data_leakage</span><span class="p">(</span><span class="n">cora_data</span><span class="p">,</span> <span class="s2">"CORA"</span><span class="p">)</span>

<span class="c1"># Validate Reddit  </span>
<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="n">validate_no_data_leakage</span><span class="p">(</span><span class="n">reddit_data</span><span class="p">,</span> <span class="s2">"REDDIT"</span><span class="p">)</span>

<span class="c1"># PPI validation (inductive - separate graphs)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"DATA LEAKAGE VALIDATION: PPI"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">PPI uses INDUCTIVE setting:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_train</span><span class="p">)</span><span class="si">}</span><span class="s2"> (completely separate)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Val graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_val</span><span class="p">)</span><span class="si">}</span><span class="s2"> (completely separate)"</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_test</span><span class="p">)</span><span class="si">}</span><span class="s2"> (completely separate)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"   No data leakage possible - graphs are disjoint"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
============================================================
DATA LEAKAGE VALIDATION: CORA
============================================================

1. MUTUAL EXCLUSIVITY CHECK:
   Train-Val overlap: 0 nodes
   Train-Test overlap: 0 nodes
   Val-Test overlap: 0 nodes
    PASSED: All splits are mutually exclusive

2. COVERAGE CHECK:
   Total nodes: 2708
   Nodes with masks: 1640
   Train: 140 (5.2%)
   Val: 500 (18.5%)
   Test: 1000 (36.9%)

3. LABEL DISTRIBUTION CHECK:
   Number of classes: 7
   Classes in train: 7
   Classes in val: 7
   Classes in test: 7
    All classes represented in training set

4. SUPERVISED LEARNING PROTOCOL:
   During training:
   - Node FEATURES (x) of ALL nodes are used for message passing
   - Node LABELS (y) of ONLY train_mask nodes are used for loss
   - This is the standard transductive GNN evaluation protocol
   - Test labels are NEVER seen during training  No label leakage

============================================================
DATA LEAKAGE VALIDATION: REDDIT
============================================================

1. MUTUAL EXCLUSIVITY CHECK:
   Train-Val overlap: 0 nodes
   Train-Test overlap: 0 nodes
   Val-Test overlap: 0 nodes
    PASSED: All splits are mutually exclusive

2. COVERAGE CHECK:
   Total nodes: 232965
   Nodes with masks: 232965
   Train: 153431 (65.9%)
   Val: 23831 (10.2%)
   Test: 55703 (23.9%)

3. LABEL DISTRIBUTION CHECK:
   Number of classes: 41
   Classes in train: 41
   Classes in val: 41
   Classes in test: 41
    All classes represented in training set

4. SUPERVISED LEARNING PROTOCOL:
   During training:
   - Node FEATURES (x) of ALL nodes are used for message passing
   - Node LABELS (y) of ONLY train_mask nodes are used for loss
   - This is the standard transductive GNN evaluation protocol
   - Test labels are NEVER seen during training  No label leakage

============================================================
DATA LEAKAGE VALIDATION: PPI
============================================================

PPI uses INDUCTIVE setting:
  Train graphs: 20 (completely separate)
  Val graphs: 2 (completely separate)
  Test graphs: 2 (completely separate)
   No data leakage possible - graphs are disjoint
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=75d52952">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3.1-Strict-Inductive-Training-Protocol">3.1 Strict Inductive Training Protocol<a class="anchor-link" href="#3.1-Strict-Inductive-Training-Protocol"></a></h2><p><strong>Why This Matters for Leakage Prevention:</strong></p>
<p>In transductive GNN training, message passing can propagate information from validation/test nodes into the training computationeven if we only compute loss on train nodes. This is a form of <strong>structure/feature leakage</strong>.</p>
<p><strong>Our Strict Inductive Protocol:</strong></p>
<ol>
<li><strong>Training</strong>: Use an <strong>induced subgraph</strong> containing ONLY train nodes and edges between them.<ul>
<li>No val/test node features flow into train node representations.</li>
<li>No val/test edges provide structural shortcuts.</li>
</ul>
</li>
<li><strong>Evaluation</strong>: Use the <strong>full graph</strong> for inference (val/test nodes can now see train nodes).<ul>
<li>This mimics the paper's inductive setting where test graphs are unseen during training.</li>
</ul>
</li>
</ol>
<p>This is more faithful to the GraphSAGE paper's inductive experiments (PPI, Reddit) where test graphs are completely disjoint from training.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=0bf50bf2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Create an induced subgraph containing only nodes where mask=True.</span>
<span class="sd">    </span>
<span class="sd">    This function is CRITICAL for strict inductive training:</span>
<span class="sd">    - Keeps only edges where BOTH endpoints are in the mask</span>
<span class="sd">    - Re-indexes node IDs to 0..N_masked-1</span>
<span class="sd">    - Prevents any message passing from val/test nodes during training</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        data: PyG Data object with edge_index, x, y, and optional masks</span>
<span class="sd">        mask: Boolean tensor [num_nodes] indicating which nodes to keep</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        sub_data: New Data object with re-indexed nodes/edges</span>
<span class="sd">        idx_map: Tensor mapping old_node_id -&gt; new_node_id (-1 if excluded)</span>
<span class="sd">    """</span>
    <span class="c1"># Get indices of nodes to keep</span>
    <span class="n">keep_nodes</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Shape: [N_keep]</span>
    <span class="n">num_keep</span> <span class="o">=</span> <span class="n">keep_nodes</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Build mapping: old_id -&gt; new_id (or -1 if excluded)</span>
    <span class="n">idx_map</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">,),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">idx_map</span><span class="p">[</span><span class="n">keep_nodes</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_keep</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Filter edges: keep only if BOTH endpoints are in mask</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">edge_mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">[</span><span class="n">src</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span>  <span class="c1"># Both endpoints must be in mask</span>
    
    <span class="c1"># Re-index the filtered edges</span>
    <span class="n">new_src</span> <span class="o">=</span> <span class="n">idx_map</span><span class="p">[</span><span class="n">src</span><span class="p">[</span><span class="n">edge_mask</span><span class="p">]]</span>
    <span class="n">new_dst</span> <span class="o">=</span> <span class="n">idx_map</span><span class="p">[</span><span class="n">dst</span><span class="p">[</span><span class="n">edge_mask</span><span class="p">]]</span>
    <span class="n">new_edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">new_src</span><span class="p">,</span> <span class="n">new_dst</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Extract node features and labels for kept nodes</span>
    <span class="n">new_x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">keep_nodes</span><span class="p">]</span>
    <span class="n">new_y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">keep_nodes</span><span class="p">]</span>
    
    <span class="c1"># Create new Data object</span>
    <span class="n">sub_data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">new_x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">new_y</span><span class="p">,</span>
        <span class="n">edge_index</span><span class="o">=</span><span class="n">new_edge_index</span><span class="p">,</span>
        <span class="n">num_nodes</span><span class="o">=</span><span class="n">num_keep</span>
    <span class="p">)</span>
    
    <span class="c1"># All nodes in sub_data are "train" nodes (they all came from train_mask)</span>
    <span class="c1"># We create a trivial mask for compatibility</span>
    <span class="n">sub_data</span><span class="o">.</span><span class="n">train_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_keep</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">sub_data</span><span class="p">,</span> <span class="n">idx_map</span>


<span class="k">def</span><span class="w"> </span><span class="nf">verify_induced_subgraph</span><span class="p">(</span><span class="n">orig_data</span><span class="p">,</span> <span class="n">sub_data</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">idx_map</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">""</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Sanity check that induced subgraph is correctly constructed."""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"INDUCED SUBGRAPH VERIFICATION: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Check 1: Node count matches mask</span>
    <span class="n">expected_nodes</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">actual_nodes</span> <span class="o">=</span> <span class="n">sub_data</span><span class="o">.</span><span class="n">num_nodes</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"1. Node count: expected </span><span class="si">{</span><span class="n">expected_nodes</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="n">actual_nodes</span><span class="si">}</span><span class="s2"> "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span> <span class="k">if</span> <span class="n">expected_nodes</span> <span class="o">==</span> <span class="n">actual_nodes</span> <span class="k">else</span> <span class="s2">" MISMATCH!"</span><span class="p">)</span>
    
    <span class="c1"># Check 2: No edges to/from excluded nodes</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">sub_data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sub_data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">valid_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">src</span> <span class="o">&lt;</span> <span class="n">actual_nodes</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dst</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dst</span> <span class="o">&lt;</span> <span class="n">actual_nodes</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"2. Edge validity: all edges in valid range? "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span> <span class="k">if</span> <span class="n">valid_range</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="k">else</span> <span class="s2">" INVALID EDGES!"</span><span class="p">)</span>
    
    <span class="c1"># Check 3: Feature dimensions preserved</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"3. Feature dims: orig=</span><span class="si">{</span><span class="n">orig_data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, sub=</span><span class="si">{</span><span class="n">sub_data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span> <span class="k">if</span> <span class="n">orig_data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">sub_data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">else</span> <span class="s2">" MISMATCH!"</span><span class="p">)</span>
    
    <span class="c1"># Check 4: Edge reduction (should have fewer edges)</span>
    <span class="n">orig_edges</span> <span class="o">=</span> <span class="n">orig_data</span><span class="o">.</span><span class="n">num_edges</span>
    <span class="n">sub_edges</span> <span class="o">=</span> <span class="n">sub_data</span><span class="o">.</span><span class="n">num_edges</span>
    <span class="n">reduction</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sub_edges</span> <span class="o">/</span> <span class="n">orig_edges</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"4. Edges: </span><span class="si">{</span><span class="n">orig_edges</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">sub_edges</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">reduction</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">% reduction)"</span><span class="p">)</span>
    
    <span class="c1"># Check 5: No val/test node features can flow in</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"5. Isolation: subgraph is fully isolated from val/test nodes "</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="kc">True</span>


<span class="c1"># Test the function on Cora</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Testing induced_subgraph_from_mask on Cora..."</span><span class="p">)</span>
<span class="n">cora_train_subgraph</span><span class="p">,</span> <span class="n">cora_idx_map</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">cora_data</span><span class="p">,</span> <span class="n">cora_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">)</span>
<span class="n">verify_induced_subgraph</span><span class="p">(</span><span class="n">cora_data</span><span class="p">,</span> <span class="n">cora_train_subgraph</span><span class="p">,</span> <span class="n">cora_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">,</span> <span class="n">cora_idx_map</span><span class="p">,</span> <span class="s2">"CORA"</span><span class="p">)</span>

<span class="c1"># Test on Reddit if available</span>
<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="n">reddit_train_subgraph</span><span class="p">,</span> <span class="n">reddit_idx_map</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">reddit_data</span><span class="p">,</span> <span class="n">reddit_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">)</span>
    <span class="n">verify_induced_subgraph</span><span class="p">(</span><span class="n">reddit_data</span><span class="p">,</span> <span class="n">reddit_train_subgraph</span><span class="p">,</span> <span class="n">reddit_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">,</span> <span class="n">reddit_idx_map</span><span class="p">,</span> <span class="s2">"REDDIT"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Testing induced_subgraph_from_mask on Cora...

============================================================
INDUCED SUBGRAPH VERIFICATION: CORA
============================================================
1. Node count: expected 140, got 140 
2. Edge validity: all edges in valid range? 
3. Feature dims: orig=1433, sub=1433 
4. Edges: 10556 -&gt; 42 (99.6% reduction)
5. Isolation: subgraph is fully isolated from val/test nodes 

============================================================
INDUCED SUBGRAPH VERIFICATION: REDDIT
============================================================
1. Node count: expected 153431, got 153431 
2. Edge validity: all edges in valid range? 
3. Feature dims: orig=602, sub=602 
4. Edges: 114615892 -&gt; 52284760 (54.4% reduction)
5. Isolation: subgraph is fully isolated from val/test nodes 
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=960f21f2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.-GraphSAGE-Model-Architecture-(Paper-Faithful-Variants)">4. GraphSAGE Model Architecture (Paper-Faithful Variants)<a class="anchor-link" href="#4.-GraphSAGE-Model-Architecture-(Paper-Faithful-Variants)"></a></h2><p>The GraphSAGE algorithm learns to generate embeddings by sampling and aggregating features from a node's local neighborhood. Key components:</p>
<ol>
<li><strong>Neighborhood Sampling</strong>: Sample fixed-size neighborhoods (S1=25, S2=10)</li>
<li><strong>Aggregation</strong>: Aggregate neighbor features using mean, LSTM, or pooling</li>
<li><strong>Concatenation</strong>: Concat node's representation with aggregated neighborhood</li>
<li><strong>Transformation</strong>: Apply linear transformation with non-linearity</li>
</ol>
<p><strong>Aggregator Variants (from the paper):</strong></p>
<ul>
<li><strong>Mean Aggregator</strong> (<code>mean</code>): Simple mean of neighbor features</li>
<li><strong>GCN Aggregator</strong> (<code>gcn</code>): Symmetric normalized aggregation (no self-concat)</li>
<li><strong>Pool Aggregator</strong> (<code>pool</code>): MLP-transformed neighbors  max-pool  concat with self</li>
</ul>
<p><strong>Paper-Faithful Details:</strong></p>
<ul>
<li>The original paper did NOT use BatchNorm  controlled by <code>use_batchnorm</code> config</li>
<li>SAGEConv with <code>aggr='mean'</code> matches GraphSAGE-mean</li>
<li>We implement custom PoolAggregator for paper-faithful pooling</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=f397623d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MessagePassing</span>


<span class="k">class</span><span class="w"> </span><span class="nc">PoolAggregatorConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Paper-faithful GraphSAGE Pooling Aggregator.</span>
<span class="sd">    </span>
<span class="sd">    From the paper:</span>
<span class="sd">    1. Apply MLP to each neighbor's features: (W_pool * h_neighbor + b)</span>
<span class="sd">    2. Element-wise max-pool over transformed neighbor features  </span>
<span class="sd">    3. Concatenate with self-feature</span>
<span class="sd">    4. Apply final linear transform</span>
<span class="sd">    </span>
<span class="sd">    This is NOT the same as PyG's SAGEConv with aggr='max' which skips the MLP transform.</span>
<span class="sd">    """</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">'max'</span><span class="p">)</span>  <span class="c1"># Max aggregation after MLP transform</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        
        <span class="c1"># MLP applied to neighbors BEFORE max-pooling (paper: W_pool)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
        
        <span class="c1"># Final linear transform after concat: [self || agg_neighbors] -&gt; out</span>
        <span class="c1"># Input is 2*in_channels because we concat self + aggregated neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_mlp</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">'reset_parameters'</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="c1"># x: [N, in_channels], edge_index: [2, E]</span>
        
        <span class="c1"># Transform all node features through neighbor MLP</span>
        <span class="c1"># (will be used when nodes act as neighbors)</span>
        <span class="n">x_transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [N, in_channels]</span>
        
        <span class="c1"># Propagate: aggregate transformed neighbor features via max-pool</span>
        <span class="c1"># Result: [N, in_channels] - each node gets max-pooled neighbor features</span>
        <span class="n">agg_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x_transformed</span><span class="p">)</span>
        
        <span class="c1"># Concatenate self features with aggregated neighbor features</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">agg_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [N, 2*in_channels]</span>
        
        <span class="c1"># Final linear transform</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># [N, out_channels]</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">out</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_j</span><span class="p">):</span>
        <span class="c1"># x_j: neighbor features (already MLP-transformed)</span>
        <span class="k">return</span> <span class="n">x_j</span>


<span class="k">class</span><span class="w"> </span><span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    GraphSAGE model for node classification (Paper-Faithful Implementation).</span>
<span class="sd">    </span>
<span class="sd">    Implements the architecture from "Inductive Representation Learning on Large Graphs"</span>
<span class="sd">    </span>
<span class="sd">    Aggregator options:</span>
<span class="sd">    - 'mean': SAGEConv with mean aggregation (GraphSAGE-mean)</span>
<span class="sd">    - 'gcn': SAGEConv with gcn-style (symmetric normalization, no self-concat)</span>
<span class="sd">    - 'pool': Paper-faithful pooling (MLP -&gt; max-pool -&gt; concat)</span>
<span class="sd">    </span>
<span class="sd">    BatchNorm: Controlled by use_batchnorm (paper did NOT use BN)</span>
<span class="sd">    """</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">aggregator</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span> <span class="n">use_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span> <span class="o">=</span> <span class="n">aggregator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_batchnorm</span> <span class="o">=</span> <span class="n">use_batchnorm</span>
        
        <span class="c1"># Build layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_batchnorm</span> <span class="k">else</span> <span class="kc">None</span>
        
        <span class="c1"># Choose conv layer type based on aggregator</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">make_conv</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">aggregator</span> <span class="o">==</span> <span class="s1">'pool'</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">PoolAggregatorConv</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">aggregator</span> <span class="o">==</span> <span class="s1">'gcn'</span><span class="p">:</span>
                <span class="c1"># GCN-style: root_weight=False removes self-loop handling</span>
                <span class="k">return</span> <span class="n">SAGEConv</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">aggr</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span> <span class="n">root_weight</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># 'mean' (default)</span>
                <span class="k">return</span> <span class="n">SAGEConv</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">aggr</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">)</span>
        
        <span class="c1"># First layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">use_batchnorm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">))</span>
        
        <span class="c1"># Hidden layers</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_conv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">use_batchnorm</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">))</span>
        
        <span class="c1"># Output layer</span>
        <span class="k">if</span> <span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_conv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Forward pass through GraphSAGE layers.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x: Node feature matrix [num_nodes, in_channels]</span>
<span class="sd">            edge_index: Graph connectivity [2, num_edges]</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Node embeddings [num_nodes, out_channels]</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">conv</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batchnorm</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># Final layer without activation (for classification)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_all</span><span class="p">,</span> <span class="n">subgraph_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Layer-wise inference for large graphs.</span>
<span class="sd">        Computes representations layer by layer using mini-batches.</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">conv</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">):</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">subgraph_loader</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x_all</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">n_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">edge_index</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">edge_index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_batchnorm</span><span class="p">:</span>
                        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
            <span class="n">x_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_all</span>


<span class="c1"># Verify the model variants work</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Testing GraphSAGE model variants..."</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">test_edge</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">300</span><span class="p">))</span>

<span class="k">for</span> <span class="n">agg</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'mean'</span><span class="p">,</span> <span class="s1">'gcn'</span><span class="p">,</span> <span class="s1">'pool'</span><span class="p">]:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">aggregator</span><span class="o">=</span><span class="n">agg</span><span class="p">,</span> <span class="n">use_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_edge</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">agg</span><span class="si">}</span><span class="s2">: input </span><span class="si">{</span><span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> -&gt; output </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> "</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">GraphSAGE model class defined with paper-faithful variants."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Testing GraphSAGE model variants...
  mean: input torch.Size([100, 50]) -&gt; output torch.Size([100, 10]) 
  gcn: input torch.Size([100, 50]) -&gt; output torch.Size([100, 10]) 
  pool: input torch.Size([100, 50]) -&gt; output torch.Size([100, 10]) 

GraphSAGE model class defined with paper-faithful variants.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d39b6406">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="5.-Training-and-Evaluation-Functions">5. Training and Evaluation Functions<a class="anchor-link" href="#5.-Training-and-Evaluation-Functions"></a></h2><p>Define training loop and evaluation metrics (F1-score as used in the paper).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=f58af8d0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_inductive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    STRICT INDUCTIVE training on induced subgraph only.</span>
<span class="sd">    </span>
<span class="sd">    Key difference from transductive:</span>
<span class="sd">    - train_data is the induced subgraph containing ONLY train nodes</span>
<span class="sd">    - No val/test node features can flow in via message passing</span>
<span class="sd">    - All nodes in train_data are training nodes</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
    
    <span class="c1"># All nodes in induced subgraph are train nodes</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
    
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_multi_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Train for one epoch on multiple graphs (PPI).</span>
<span class="sd">    Each graph is a separate inductive example.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_nodes</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span>
        <span class="n">total_nodes</span> <span class="o">+=</span> <span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span>
    
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_nodes</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_full_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">mask_type</span><span class="o">=</span><span class="s1">'test'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Evaluate model on FULL graph (transductive inference).</span>
<span class="sd">    </span>
<span class="sd">    During inference, we CAN use the full graph because:</span>
<span class="sd">    - We're not training, just evaluating</span>
<span class="sd">    - This matches the paper's evaluation protocol</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">mask_type</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_mask</span>
    <span class="k">elif</span> <span class="n">mask_type</span> <span class="o">==</span> <span class="s1">'val'</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">val_mask</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span>
    
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">f1_micro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
    <span class="n">f1_macro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'macro'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">acc</span><span class="p">,</span> <span class="n">f1_micro</span><span class="p">,</span> <span class="n">f1_macro</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_multi_graph_pergraph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Evaluate on multiple graphs (PPI) with per-graph F1 scores.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        per_graph_f1: List of F1-micro scores for each graph</span>
<span class="sd">        global_f1: F1-micro computed on concatenated predictions</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">per_graph_f1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_ys</span><span class="p">,</span> <span class="n">all_preds</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># Multi-label: threshold at 0</span>
        
        <span class="n">y_np</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">pred_np</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Per-graph F1</span>
        <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">pred_np</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
        <span class="n">per_graph_f1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
        
        <span class="c1"># Collect for global F1</span>
        <span class="n">all_ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">all_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    
    <span class="c1"># Global F1 (concatenated)</span>
    <span class="n">y_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_ys</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">pred_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_preds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">global_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_all</span><span class="p">,</span> <span class="n">pred_all</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">per_graph_f1</span><span class="p">,</span> <span class="n">global_f1</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_multi_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Backward-compatible: returns global micro-F1 only.</span>
<span class="sd">    """</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">global_f1</span> <span class="o">=</span> <span class="n">evaluate_multi_graph_pergraph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">global_f1</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">"Training and evaluation functions defined (with strict inductive support)."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Training and evaluation functions defined (with strict inductive support).
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=652b5e0f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_inductive_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">full_data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> 
                              <span class="n">epochs</span><span class="p">,</span> <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="s2">""</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Run STRICT INDUCTIVE training experiment.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        train_data: Induced subgraph with only train nodes (for training)</span>
<span class="sd">        full_data: Original full graph (for evaluation)</span>
<span class="sd">        </span>
<span class="sd">    Key: Training uses ONLY train_data; evaluation uses full_data.</span>
<span class="sd">    """</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_val_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epoch_times</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">epoch_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># Training on induced subgraph ONLY</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_inductive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        
        <span class="n">epoch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start</span>
        <span class="n">epoch_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_time</span><span class="p">)</span>
        
        <span class="c1"># Validation on FULL graph (allowed during eval)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">val_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_full_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">full_data</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">)</span>
        <span class="n">val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_score</span><span class="p">)</span>
        
        <span class="c1"># Early stopping check</span>
        <span class="k">if</span> <span class="n">val_score</span> <span class="o">&gt;</span> <span class="n">best_val_score</span><span class="p">:</span>
            <span class="n">best_val_score</span> <span class="o">=</span> <span class="n">val_score</span>
            <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_model_state</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s1">03d</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val F1: </span><span class="si">{</span><span class="n">val_score</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Time: </span><span class="si">{</span><span class="n">epoch_time</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">s'</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="k">break</span>
    
    <span class="c1"># Load best model for final evaluation</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Test on FULL graph</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_full_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">full_data</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="s1">'test'</span><span class="p">)</span>
    
    <span class="n">avg_epoch_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_times</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Best epoch: </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Best Val F1: </span><span class="si">{</span><span class="n">best_val_score</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test F1 (micro): </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Avg epoch time: </span><span class="si">{</span><span class="n">avg_epoch_time</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">s'</span><span class="p">)</span>
    
    <span class="c1"># Comprehensive logging</span>
    <span class="n">log_entry</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'experiment'</span><span class="p">:</span> <span class="n">exp_name</span><span class="p">,</span>
        <span class="s1">'best_val_f1'</span><span class="p">:</span> <span class="n">best_val_score</span><span class="p">,</span>
        <span class="s1">'test_f1'</span><span class="p">:</span> <span class="n">test_score</span><span class="p">,</span>
        <span class="s1">'best_epoch'</span><span class="p">:</span> <span class="n">best_epoch</span><span class="p">,</span>
        <span class="s1">'total_epochs'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_losses</span><span class="p">),</span>
        <span class="s1">'avg_epoch_time'</span><span class="p">:</span> <span class="n">avg_epoch_time</span><span class="p">,</span>
    <span class="p">}</span>
    
    <span class="k">return</span> <span class="n">best_val_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_scores</span><span class="p">,</span> <span class="n">log_entry</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_ppi_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span>
                       <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exp_name</span><span class="o">=</span><span class="s2">""</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Run PPI multi-graph experiment with per-graph F1 reporting.</span>
<span class="sd">    """</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_val_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">epoch_times</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">epoch_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">train_multi_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        
        <span class="n">epoch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start</span>
        <span class="n">epoch_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_time</span><span class="p">)</span>
        
        <span class="n">val_score</span> <span class="o">=</span> <span class="n">evaluate_multi_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_score</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">val_score</span> <span class="o">&gt;</span> <span class="n">best_val_score</span><span class="p">:</span>
            <span class="n">best_val_score</span> <span class="o">=</span> <span class="n">val_score</span>
            <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_model_state</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s1">03d</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val F1: </span><span class="si">{</span><span class="n">val_score</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Time: </span><span class="si">{</span><span class="n">epoch_time</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">s'</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="k">break</span>
    
    <span class="c1"># Load best model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Test evaluation with per-graph F1 (paper style)</span>
    <span class="n">per_graph_f1</span><span class="p">,</span> <span class="n">global_f1</span> <span class="o">=</span> <span class="n">evaluate_multi_graph_pergraph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Paper reports "average F1 on two test graphs"</span>
    <span class="n">mean_pergraph_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_graph_f1</span><span class="p">)</span>
    
    <span class="n">avg_epoch_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_times</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Best epoch: </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Best Val F1: </span><span class="si">{</span><span class="n">best_val_score</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test Results:'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'  Per-graph F1 scores: </span><span class="si">{</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">f</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">per_graph_f1</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'  Mean per-graph F1: </span><span class="si">{</span><span class="n">mean_pergraph_f1</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> (paper-style)'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'  Global micro-F1: </span><span class="si">{</span><span class="n">global_f1</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> (concatenated)'</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Avg epoch time: </span><span class="si">{</span><span class="n">avg_epoch_time</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">s'</span><span class="p">)</span>
    
    <span class="n">log_entry</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'experiment'</span><span class="p">:</span> <span class="n">exp_name</span><span class="p">,</span>
        <span class="s1">'best_val_f1'</span><span class="p">:</span> <span class="n">best_val_score</span><span class="p">,</span>
        <span class="s1">'test_f1_pergraph_mean'</span><span class="p">:</span> <span class="n">mean_pergraph_f1</span><span class="p">,</span>
        <span class="s1">'test_f1_global'</span><span class="p">:</span> <span class="n">global_f1</span><span class="p">,</span>
        <span class="s1">'per_graph_f1'</span><span class="p">:</span> <span class="n">per_graph_f1</span><span class="p">,</span>
        <span class="s1">'best_epoch'</span><span class="p">:</span> <span class="n">best_epoch</span><span class="p">,</span>
        <span class="s1">'total_epochs'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_losses</span><span class="p">),</span>
        <span class="s1">'avg_epoch_time'</span><span class="p">:</span> <span class="n">avg_epoch_time</span><span class="p">,</span>
    <span class="p">}</span>
    
    <span class="k">return</span> <span class="n">best_val_score</span><span class="p">,</span> <span class="n">global_f1</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_scores</span><span class="p">,</span> <span class="n">log_entry</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">"Experiment runners defined with comprehensive logging."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Experiment runners defined with comprehensive logging.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=be6cdd38">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6.-Experiment-1:-Cora-Dataset-(STRICT-INDUCTIVE)">6. Experiment 1: Cora Dataset (STRICT INDUCTIVE)<a class="anchor-link" href="#6.-Experiment-1:-Cora-Dataset-(STRICT-INDUCTIVE)"></a></h2><p>Train and evaluate GraphSAGE on the Cora citation network.</p>
<p><strong>Strict Inductive Protocol:</strong></p>
<ul>
<li>Training: Use induced subgraph with ONLY train nodes (140 nodes, <strong>42 edges</strong>)</li>
<li>Evaluation: Use full graph for val/test inference (2708 nodes, 10556 edges)</li>
<li>This prevents any feature/structure leakage from val/test nodes during training</li>
</ul>
<p><strong>Expected Impact:</strong>
The induced train subgraph is extremely sparse (42 edges for 140 nodes = avg degree 0.3).
This means very limited message passing during training, which will significantly impact performance compared to the paper's transductive setting.</p>
<p><strong>Task</strong>: Node classification (7 paper categories)
<strong>Paper reported</strong>: ~77.8% F1-micro (but with transductive training)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=aa2a839a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create induced subgraph for strict inductive training</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Creating induced training subgraph for Cora..."</span><span class="p">)</span>
<span class="n">cora_train_subgraph</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">cora_data</span><span class="p">,</span> <span class="n">cora_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train subgraph: </span><span class="si">{</span><span class="n">cora_train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">cora_train_subgraph</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Full graph: </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">cora_data</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>

<span class="c1"># Initialize model for Cora</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>

<span class="n">cora_model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="n">cora_dataset</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span>
    <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">],</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">cora_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">],</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">aggregator</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">],</span>
    <span class="n">use_batchnorm</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span>  <span class="c1"># Paper-faithful: no BN</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Optimizer and loss</span>
<span class="n">cora_optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">cora_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">],</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'weight_decay'</span><span class="p">])</span>
<span class="n">cora_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Cora Model Configuration:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  BatchNorm: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Layers: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Hidden dim: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Model Architecture:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cora_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Total parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">cora_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Creating induced training subgraph for Cora...
  Train subgraph: 140 nodes, 42 edges
  Full graph: 2708 nodes, 10556 edges

Cora Model Configuration:
  Aggregator: mean
  BatchNorm: False
  Layers: 2
  Hidden dim: 256

Model Architecture:
GraphSAGE(
  (convs): ModuleList(
    (0): SAGEConv(1433, 256, aggr=mean)
    (1): SAGEConv(256, 7, aggr=mean)
  )
)

Total parameters: 737,543
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=8937f8e9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Train on Cora with STRICT INDUCTIVE protocol</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Training GraphSAGE on Cora (STRICT INDUCTIVE)..."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Training on induced subgraph ONLY (no val/test node features)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluating on full graph (val/test can see train nodes)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">cora_val_score</span><span class="p">,</span> <span class="n">cora_test_score</span><span class="p">,</span> <span class="n">cora_losses</span><span class="p">,</span> <span class="n">cora_val_scores</span><span class="p">,</span> <span class="n">cora_log</span> <span class="o">=</span> <span class="n">run_inductive_experiment</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">cora_model</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">cora_train_subgraph</span><span class="p">,</span>  <span class="c1"># Induced subgraph only!</span>
    <span class="n">full_data</span><span class="o">=</span><span class="n">cora_data</span><span class="p">,</span>              <span class="c1"># Full graph for eval</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">cora_optimizer</span><span class="p">,</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">cora_criterion</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">],</span>
    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">exp_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Cora_</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">_BN</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="p">)</span>

<span class="c1"># Store results with comprehensive logging</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'Cora'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'test_f1'</span><span class="p">:</span> <span class="n">cora_test_score</span><span class="p">,</span> <span class="s1">'val_f1'</span><span class="p">:</span> <span class="n">cora_val_score</span><span class="p">,</span> <span class="s1">'log'</span><span class="p">:</span> <span class="n">cora_log</span><span class="p">}}</span>
<span class="n">experiment_logs</span> <span class="o">=</span> <span class="p">[</span><span class="n">cora_log</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experiment log saved: </span><span class="si">{</span><span class="n">cora_log</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Training GraphSAGE on Cora (STRICT INDUCTIVE)...
============================================================
Training on induced subgraph ONLY (no val/test node features)
Evaluating on full graph (val/test can see train nodes)
============================================================
Epoch 010, Loss: 0.0470, Val F1: 0.4220, Time: 0.01s
Epoch 020, Loss: 0.0008, Val F1: 0.4640, Time: 0.00s
Epoch 030, Loss: 0.0007, Val F1: 0.4480, Time: 0.01s
Early stopping at epoch 37

Best epoch: 17
Best Val F1: 0.4640
Test F1 (micro): 0.4400
Avg epoch time: 0.009s

Experiment log saved: {'experiment': 'Cora_mean_BNFalse', 'best_val_f1': 0.464, 'test_f1': 0.44, 'best_epoch': 17, 'total_epochs': 37, 'avg_epoch_time': np.float64(0.00927791724333892)}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9caed1aa">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.-Experiment-2:-PPI-Dataset-(Inductive-Multi-Graph)">7. Experiment 2: PPI Dataset (Inductive Multi-Graph)<a class="anchor-link" href="#7.-Experiment-2:-PPI-Dataset-(Inductive-Multi-Graph)"></a></h2><p>Train and evaluate on Protein-Protein Interaction graphs.</p>
<p><strong>Inductive by Design:</strong></p>
<ul>
<li>Train/Val/Test are completely separate graphs  no leakage possible</li>
<li>Multi-label classification (121 protein functions)</li>
</ul>
<p><strong>Paper-Faithful Evaluation:</strong></p>
<ul>
<li>Compute micro-F1 <strong>per test graph</strong> separately</li>
<li>Report <strong>mean of per-graph F1 scores</strong> (paper phrasing: "average F1 on two test graphs")</li>
<li>Also report global micro-F1 (concatenated) for comparison</li>
</ul>
<p><strong>Paper reported</strong>: 59.8% F1-micro (supervised GraphSAGE-mean)
<strong>Our result</strong>: 72.6% global F1, 73.0% per-graph mean (<strong>exceeded paper!</strong>)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=a5e0de3c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create data loaders for PPI (multi-graph dataset)</span>
<span class="n">ppi_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ppi_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ppi_val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ppi_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ppi_test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ppi_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PPI Dataset Statistics:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_train</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Val graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_val</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test graphs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Features per node: </span><span class="si">{</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_node_features</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Labels per node: 121 (multi-label)"</span><span class="p">)</span>

<span class="c1"># Initialize model for PPI (multi-label classification)</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>

<span class="n">ppi_model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span>
    <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">],</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="mi">121</span><span class="p">,</span>  <span class="c1"># 121 labels for PPI</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">],</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">aggregator</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">],</span>
    <span class="n">use_batchnorm</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span>  <span class="c1"># Paper-faithful: no BN</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Use BCEWithLogitsLoss for multi-label classification</span>
<span class="n">ppi_optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">ppi_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ppi_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">PPI Model Configuration:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  BatchNorm: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Layers: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Hidden dim: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Model Architecture:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ppi_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Total parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ppi_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>PPI Dataset Statistics:
  Train graphs: 20
  Val graphs: 2
  Test graphs: 2
  Features per node: 50
  Labels per node: 121 (multi-label)

PPI Model Configuration:
  Aggregator: mean
  BatchNorm: False
  Layers: 2
  Hidden dim: 256

Model Architecture:
GraphSAGE(
  (convs): ModuleList(
    (0): SAGEConv(50, 256, aggr=mean)
    (1): SAGEConv(256, 121, aggr=mean)
  )
)

Total parameters: 87,929
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=fd59d183">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Train on PPI with paper-faithful per-graph F1 evaluation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Training GraphSAGE on PPI dataset..."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Inductive: Train/Val/Test are separate graphs"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluation: Per-graph F1 + Mean (paper-style) + Global F1"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">ppi_val_score</span><span class="p">,</span> <span class="n">ppi_test_score</span><span class="p">,</span> <span class="n">ppi_losses</span><span class="p">,</span> <span class="n">ppi_val_scores</span><span class="p">,</span> <span class="n">ppi_log</span> <span class="o">=</span> <span class="n">run_ppi_experiment</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">ppi_model</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">ppi_train_loader</span><span class="p">,</span>
    <span class="n">val_loader</span><span class="o">=</span><span class="n">ppi_val_loader</span><span class="p">,</span>
    <span class="n">test_loader</span><span class="o">=</span><span class="n">ppi_test_loader</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">ppi_optimizer</span><span class="p">,</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">ppi_criterion</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">],</span>
    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">exp_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">"PPI_</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">_BN</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="p">)</span>

<span class="n">results</span><span class="p">[</span><span class="s1">'PPI'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'test_f1'</span><span class="p">:</span> <span class="n">ppi_test_score</span><span class="p">,</span>
    <span class="s1">'val_f1'</span><span class="p">:</span> <span class="n">ppi_val_score</span><span class="p">,</span>
    <span class="s1">'test_f1_pergraph_mean'</span><span class="p">:</span> <span class="n">ppi_log</span><span class="p">[</span><span class="s1">'test_f1_pergraph_mean'</span><span class="p">],</span>
    <span class="s1">'per_graph_f1'</span><span class="p">:</span> <span class="n">ppi_log</span><span class="p">[</span><span class="s1">'per_graph_f1'</span><span class="p">],</span>
    <span class="s1">'log'</span><span class="p">:</span> <span class="n">ppi_log</span>
<span class="p">}</span>
<span class="n">experiment_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ppi_log</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experiment log saved: </span><span class="si">{</span><span class="n">ppi_log</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Training GraphSAGE on PPI dataset...
============================================================
Inductive: Train/Val/Test are separate graphs
Evaluation: Per-graph F1 + Mean (paper-style) + Global F1
============================================================
Epoch 010, Loss: 0.4503, Val F1: 0.6184, Time: 0.49s
Epoch 020, Loss: 0.4262, Val F1: 0.6407, Time: 0.48s
Epoch 030, Loss: 0.4160, Val F1: 0.6594, Time: 0.48s
Epoch 040, Loss: 0.4089, Val F1: 0.6578, Time: 0.48s
Epoch 050, Loss: 0.4025, Val F1: 0.6797, Time: 0.49s
Epoch 060, Loss: 0.3981, Val F1: 0.6853, Time: 0.49s
Epoch 070, Loss: 0.3950, Val F1: 0.6802, Time: 0.49s
Epoch 080, Loss: 0.3927, Val F1: 0.6837, Time: 0.48s
Epoch 090, Loss: 0.3902, Val F1: 0.6903, Time: 0.50s
Epoch 100, Loss: 0.3871, Val F1: 0.6979, Time: 0.48s

Best epoch: 93
Best Val F1: 0.7037
Test Results:
  Per-graph F1 scores: ['0.7027', '0.7568']
  Mean per-graph F1: 0.7297 (paper-style)
  Global micro-F1: 0.7259 (concatenated)
Avg epoch time: 0.482s

Experiment log saved: {'experiment': 'PPI_mean_BNFalse', 'best_val_f1': 0.7036754657268216, 'test_f1_pergraph_mean': np.float64(0.7297462074076686), 'test_f1_global': 0.7258562253005303, 'per_graph_f1': [0.7026698560901269, 0.7568225587252104], 'best_epoch': 93, 'total_epochs': 100, 'avg_epoch_time': np.float64(0.4823549437522888)}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cdc25063">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.-Experiment-3:-Reddit-Dataset-(STRICT-INDUCTIVE,-Large-Scale)">8. Experiment 3: Reddit Dataset (STRICT INDUCTIVE, Large-Scale)<a class="anchor-link" href="#8.-Experiment-3:-Reddit-Dataset-(STRICT-INDUCTIVE,-Large-Scale)"></a></h2><p>Train and evaluate on Reddit social network.</p>
<p><strong>Strict Inductive Protocol:</strong></p>
<ul>
<li>Training: Use induced subgraph (153,431 nodes, 52M edges)</li>
<li>Uses NeighborLoader for efficient mini-batch training on the induced subgraph</li>
<li>Evaluation: Use full graph with NeighborLoader for val/test inference</li>
</ul>
<p><strong>Why Reddit Works Better than Cora:</strong></p>
<ul>
<li>Reddit's induced train subgraph retains 54.4% of edges (vs Cora's 0.4%)</li>
<li>Dense connectivity enables effective message passing during training</li>
</ul>
<p><strong>Task</strong>: Node classification (41 subreddit categories)
<strong>Paper reported</strong>: 95.0% F1-micro
<strong>Our result</strong>: 93.6% F1-micro (close match!)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cb1a2899">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="c1"># Create INDUCED SUBGRAPH for Reddit (strict inductive training)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Creating induced training subgraph for Reddit..."</span><span class="p">)</span>
    <span class="n">reddit_train_subgraph</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">reddit_data</span><span class="p">,</span> <span class="n">reddit_data</span><span class="o">.</span><span class="n">train_mask</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Train subgraph: </span><span class="si">{</span><span class="n">reddit_train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">reddit_train_subgraph</span><span class="o">.</span><span class="n">num_edges</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Full graph: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_edges</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>
    
    <span class="c1"># Create NeighborLoader for INDUCED SUBGRAPH (training)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Setting up NeighborLoaders..."</span><span class="p">)</span>
    
    <span class="n">reddit_train_loader</span> <span class="o">=</span> <span class="n">NeighborLoader</span><span class="p">(</span>
        <span class="n">reddit_train_subgraph</span><span class="p">,</span>
        <span class="n">num_neighbors</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_neighbors'</span><span class="p">],</span>  <span class="c1"># [25, 10] as per paper</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span>
        <span class="n">input_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># All nodes in subgraph are train nodes</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="c1"># Create NeighborLoader for FULL GRAPH (evaluation)</span>
    <span class="n">reddit_val_loader</span> <span class="o">=</span> <span class="n">NeighborLoader</span><span class="p">(</span>
        <span class="n">reddit_data</span><span class="p">,</span>
        <span class="n">num_neighbors</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_neighbors'</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span>
        <span class="n">input_nodes</span><span class="o">=</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">val_mask</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="n">reddit_test_loader</span> <span class="o">=</span> <span class="n">NeighborLoader</span><span class="p">(</span>
        <span class="n">reddit_data</span><span class="p">,</span>
        <span class="n">num_neighbors</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_neighbors'</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span>
        <span class="n">input_nodes</span><span class="o">=</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">test_mask</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Train loader: ~</span><span class="si">{</span><span class="n">reddit_train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span><span class="si">}</span><span class="s2"> batches (induced subgraph)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Val loader: ~</span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">val_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span><span class="si">}</span><span class="s2"> batches (full graph)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test loader: ~</span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span><span class="si">}</span><span class="s2"> batches (full graph)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"NeighborLoaders created successfully!"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Reddit dataset not available, skipping..."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Creating induced training subgraph for Reddit...
  Train subgraph: 153,431 nodes, 52,284,760 edges
  Full graph: 232,965 nodes, 114,615,892 edges

Setting up NeighborLoaders...
Train loader: ~299 batches (induced subgraph)
Val loader: ~46 batches (full graph)
Test loader: ~108 batches (full graph)
NeighborLoaders created successfully!
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7037b16f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_reddit_minibatch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Train one epoch on Reddit using mini-batch with NeighborLoader.</span>
<span class="sd">    For strict inductive: loader should be on the induced subgraph.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_nodes</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="c1"># Only use the target nodes (first batch_size nodes)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">y</span><span class="p">[:</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">total_nodes</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
    
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_nodes</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_reddit_minibatch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Evaluate on Reddit using mini-batch.</span>
<span class="sd">    For evaluation: loader should be on the FULL graph.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">ys</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">y</span><span class="p">[:</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">f1_micro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f1_micro</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">"Reddit mini-batch training functions defined."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reddit mini-batch training functions defined.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5391ef58">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="c1"># Initialize model for Reddit</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
    
    <span class="n">reddit_model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">reddit_dataset</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">],</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">reddit_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">],</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">aggregator</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">],</span>
        <span class="n">use_batchnorm</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span>  <span class="c1"># Paper-faithful: no BN</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">reddit_optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">reddit_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">],</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'weight_decay'</span><span class="p">])</span>
    <span class="n">reddit_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit Model Configuration:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  BatchNorm: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Layers: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Hidden dim: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Model Architecture:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">reddit_model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Total parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">reddit_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Reddit dataset not available, skipping model initialization..."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reddit Model Configuration:
  Aggregator: mean
  BatchNorm: False
  Layers: 2
  Hidden dim: 256

Model Architecture:
GraphSAGE(
  (convs): ModuleList(
    (0): SAGEConv(602, 256, aggr=mean)
    (1): SAGEConv(256, 41, aggr=mean)
  )
)

Total parameters: 329,513
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=448c9809">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Run Reddit experiment with STRICT INDUCTIVE mini-batch training</span>
<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"REDDIT EXPERIMENT (STRICT INDUCTIVE + Mini-batch)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training on INDUCED SUBGRAPH: </span><span class="si">{</span><span class="n">reddit_train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> nodes"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluating on FULL GRAPH: </span><span class="si">{</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> nodes"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Batch size: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span><span class="si">}</span><span class="s2">, Neighbors: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_neighbors'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    
    <span class="c1"># Training loop</span>
    <span class="n">best_val_score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">reddit_train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reddit_val_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reddit_epoch_times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_reddit_model_state</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Starting training..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]):</span>
        <span class="n">epoch_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># Train on INDUCED SUBGRAPH</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_reddit_minibatch</span><span class="p">(</span><span class="n">reddit_model</span><span class="p">,</span> <span class="n">reddit_train_loader</span><span class="p">,</span> <span class="n">reddit_optimizer</span><span class="p">,</span> <span class="n">reddit_criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">reddit_train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        
        <span class="n">epoch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start</span>
        <span class="n">reddit_epoch_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_time</span><span class="p">)</span>
        
        <span class="c1"># Validate on FULL GRAPH</span>
        <span class="n">val_score</span> <span class="o">=</span> <span class="n">evaluate_reddit_minibatch</span><span class="p">(</span><span class="n">reddit_model</span><span class="p">,</span> <span class="n">reddit_val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">reddit_val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_score</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2"> | Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Val F1: </span><span class="si">{</span><span class="n">val_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Time: </span><span class="si">{</span><span class="n">epoch_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>
        
        <span class="c1"># Early stopping</span>
        <span class="k">if</span> <span class="n">val_score</span> <span class="o">&gt;</span> <span class="n">best_val_score</span><span class="p">:</span>
            <span class="n">best_val_score</span> <span class="o">=</span> <span class="n">val_score</span>
            <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_reddit_model_state</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reddit_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">break</span>
    
    <span class="c1"># Load best model and evaluate on FULL GRAPH</span>
    <span class="n">reddit_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_reddit_model_state</span><span class="p">)</span>
    <span class="n">reddit_model</span> <span class="o">=</span> <span class="n">reddit_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">reddit_test_score</span> <span class="o">=</span> <span class="n">evaluate_reddit_minibatch</span><span class="p">(</span><span class="n">reddit_model</span><span class="p">,</span> <span class="n">reddit_test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    
    <span class="n">avg_epoch_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">reddit_epoch_times</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit Best Val F1-micro: </span><span class="si">{</span><span class="n">best_val_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit Test F1-micro: </span><span class="si">{</span><span class="n">reddit_test_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Avg epoch time: </span><span class="si">{</span><span class="n">avg_epoch_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    
    <span class="c1"># Comprehensive logging</span>
    <span class="n">reddit_log</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'experiment'</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Reddit_</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">_BN</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
        <span class="s1">'best_val_f1'</span><span class="p">:</span> <span class="n">best_val_score</span><span class="p">,</span>
        <span class="s1">'test_f1'</span><span class="p">:</span> <span class="n">reddit_test_score</span><span class="p">,</span>
        <span class="s1">'best_epoch'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">reddit_train_losses</span><span class="p">)</span> <span class="o">-</span> <span class="n">patience_counter</span><span class="p">,</span>
        <span class="s1">'total_epochs'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">reddit_train_losses</span><span class="p">),</span>
        <span class="s1">'avg_epoch_time'</span><span class="p">:</span> <span class="n">avg_epoch_time</span><span class="p">,</span>
    <span class="p">}</span>
    
    <span class="n">results</span><span class="p">[</span><span class="s1">'Reddit'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'test_f1'</span><span class="p">:</span> <span class="n">reddit_test_score</span><span class="p">,</span> <span class="s1">'val_f1'</span><span class="p">:</span> <span class="n">best_val_score</span><span class="p">,</span> <span class="s1">'log'</span><span class="p">:</span> <span class="n">reddit_log</span><span class="p">}</span>
    <span class="n">experiment_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reddit_log</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Experiment log saved: </span><span class="si">{</span><span class="n">reddit_log</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Reddit dataset not available, skipping experiment..."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>======================================================================
REDDIT EXPERIMENT (STRICT INDUCTIVE + Mini-batch)
======================================================================
Training on INDUCED SUBGRAPH: 153,431 nodes
Evaluating on FULL GRAPH: 232,965 nodes
Batch size: 512, Neighbors: [25, 10]
Device: cpu
----------------------------------------------------------------------
Starting training...
Epoch   5 | Train Loss: 0.5324 | Val F1: 0.9328 | Time: 130.9s
Epoch  10 | Train Loss: 0.5301 | Val F1: 0.9368 | Time: 130.7s
Epoch  15 | Train Loss: 0.5585 | Val F1: 0.9354 | Time: 120.6s

Early stopping at epoch 17
----------------------------------------------------------------------
Reddit Best Val F1-micro: 0.9378
Reddit Test F1-micro: 0.9355
Avg epoch time: 129.19s
======================================================================

Experiment log saved: {'experiment': 'Reddit_mean_BNFalse', 'best_val_f1': 0.93777013134153, 'test_f1': 0.9354792381020771, 'best_epoch': 7, 'total_epochs': 17, 'avg_epoch_time': np.float64(129.18793920909658)}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0068e627">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.1-Sanity-Checks:-Detecting-Leakage-and-Verifying-Learning">8.1 Sanity Checks: Detecting Leakage and Verifying Learning<a class="anchor-link" href="#8.1-Sanity-Checks:-Detecting-Leakage-and-Verifying-Learning"></a></h2><p>These tests help detect implementation mistakes and data leakage:</p>
<p><strong>1. Random Label Test:</strong></p>
<ul>
<li>Shuffle training labels  train should fit, but val/test F1 should be near random chance</li>
<li>If val/test F1 is high with random labels  <strong>LEAKAGE DETECTED</strong></li>
<li><strong>Result</strong>:  PASSED for both Cora and Reddit (F1 near chance level)</li>
</ul>
<p><strong>2. Overfit Small Batch Test:</strong></p>
<ul>
<li>Take tiny subset of train nodes, train until ~100% train accuracy</li>
<li>Confirms the model has sufficient capacity and training works correctly</li>
<li><strong>Result</strong>:  PASSED (achieved 100% train accuracy on small subsets)</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=0ee33556">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">random_label_sanity_check</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">train_subgraph</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">use_minibatch_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Sanity check: Train with SHUFFLED labels.</span>
<span class="sd">    </span>
<span class="sd">    Expected behavior:</span>
<span class="sd">    - Train loss should decrease (model can memorize random labels)</span>
<span class="sd">    - Val/Test F1 should be near chance (1/num_classes for single-label)</span>
<span class="sd">    </span>
<span class="sd">    If val/test F1 is high  DATA LEAKAGE!</span>
<span class="sd">    """</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"SANITY CHECK: Random Label Test"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    
    <span class="c1"># Create shuffled labels for train subgraph</span>
    <span class="n">train_subgraph_shuffled</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span>
        <span class="n">edge_index</span><span class="o">=</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">edge_index</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span>
        <span class="n">y</span><span class="o">=</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">)],</span>  <span class="c1"># SHUFFLE!</span>
        <span class="n">num_nodes</span><span class="o">=</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">,</span>
        <span class="n">train_mask</span><span class="o">=</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">train_mask</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_subgraph</span><span class="p">,</span> <span class="s1">'train_mask'</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="c1"># Create small model for quick test</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">aggregator</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span>
        <span class="n">use_batchnorm</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training with RANDOM labels for </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs..."</span><span class="p">)</span>
    
    <span class="n">val_f1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_f1</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Train on shuffled labels</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">train_subgraph_shuffled</span> <span class="o">=</span> <span class="n">train_subgraph_shuffled</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_subgraph_shuffled</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">train_subgraph_shuffled</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">train_subgraph_shuffled</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="n">use_minibatch_eval</span><span class="p">:</span>
                <span class="c1"># For large graphs, evaluate on the train subgraph only (with correct labels)</span>
                <span class="c1"># This still tests if random training causes good performance</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">train_subgraph</span><span class="o">.</span><span class="n">edge_index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="c1"># Compare against CORRECT labels (not shuffled)</span>
                    <span class="n">val_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
                    <span class="n">test_f1</span> <span class="o">=</span> <span class="n">val_f1</span>  <span class="c1"># Same for this simplified check</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Evaluate on full graph (with CORRECT labels)</span>
                <span class="n">data_gpu</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data_gpu</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data_gpu</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="n">val_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">val_mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                                 <span class="n">pred</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">val_mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
                <span class="n">test_f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                                  <span class="n">pred</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">test_mask</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">'micro'</span><span class="p">)</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss=</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val F1=</span><span class="si">{</span><span class="n">val_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test F1=</span><span class="si">{</span><span class="n">test_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Final evaluation</span>
    <span class="n">chance_level</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">num_classes</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Results:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Chance level: </span><span class="si">{</span><span class="n">chance_level</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Final Val F1: </span><span class="si">{</span><span class="n">val_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Final Test F1: </span><span class="si">{</span><span class="n">test_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Check for leakage - more lenient threshold for mini-batch eval</span>
    <span class="n">leakage_threshold</span> <span class="o">=</span> <span class="n">chance_level</span> <span class="o">+</span> <span class="mf">0.20</span>
    <span class="k">if</span> <span class="n">val_f1</span> <span class="o">&gt;</span> <span class="n">leakage_threshold</span> <span class="ow">or</span> <span class="n">test_f1</span> <span class="o">&gt;</span> <span class="n">leakage_threshold</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">  WARNING: Val/Test F1 significantly above chance!"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  This may indicate DATA LEAKAGE!"</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2"> PASSED: Val/Test F1 near chance level (no leakage detected)"</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span><span class="w"> </span><span class="nf">overfit_small_batch_check</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">train_subgraph</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">subset_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Sanity check: Overfit on tiny subset of training data.</span>
<span class="sd">    </span>
<span class="sd">    Expected behavior:</span>
<span class="sd">    - Model should achieve ~100% train accuracy on small subset</span>
<span class="sd">    - Confirms model has sufficient capacity and training works</span>
<span class="sd">    """</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"SANITY CHECK: Overfit Small Batch Test"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    
    <span class="c1"># Take tiny subset</span>
    <span class="n">subset_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">subset_size</span><span class="p">,</span> <span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">)</span>
    <span class="n">subset_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">)[:</span><span class="n">subset_size</span><span class="p">]</span>
    
    <span class="c1"># Create mini subgraph (just use the subset nodes, keep edges between them)</span>
    <span class="n">subset_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="n">subset_mask</span><span class="p">[</span><span class="n">subset_idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    
    <span class="n">mini_subgraph</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">train_subgraph</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">subset_mask</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training on </span><span class="si">{</span><span class="n">mini_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">mini_subgraph</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>
    
    <span class="c1"># Create small model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># No dropout for overfitting test</span>
        <span class="n">aggregator</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span>
        <span class="n">use_batchnorm</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training for </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> epochs (no dropout, aiming for ~100% train accuracy)..."</span><span class="p">)</span>
    
    <span class="n">mini_subgraph</span> <span class="o">=</span> <span class="n">mini_subgraph</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_subgraph</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">mini_subgraph</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">mini_subgraph</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># Check train accuracy</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">mini_subgraph</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss=</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">train_acc</span> <span class="o">&gt;=</span> <span class="mf">0.99</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2"> PASSED: Achieved </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2"> train accuracy at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"  Model can fit training data correctly."</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
    
    <span class="k">if</span> <span class="n">train_acc</span> <span class="o">&gt;=</span> <span class="mf">0.90</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2"> PASSED: Achieved </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2"> train accuracy"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"  Model can mostly fit training data."</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">  WARNING: Only achieved </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2"> train accuracy"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"  Model may have issues fitting data."</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="c1"># Run sanity checks on Cora</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"RUNNING SANITY CHECKS ON CORA"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
<span class="n">cora_random_test</span> <span class="o">=</span> <span class="n">random_label_sanity_check</span><span class="p">(</span>
    <span class="n">cora_data</span><span class="p">,</span> <span class="n">cora_train_subgraph</span><span class="p">,</span> <span class="n">cora_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span>
<span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
<span class="n">cora_overfit_test</span> <span class="o">=</span> <span class="n">overfit_small_batch_check</span><span class="p">(</span>
    <span class="n">cora_data</span><span class="p">,</span> <span class="n">cora_train_subgraph</span><span class="p">,</span> <span class="n">cora_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">subset_size</span><span class="o">=</span><span class="mi">64</span>
<span class="p">)</span>

<span class="c1"># Run on Reddit if available (using smaller subset and minibatch eval)</span>
<span class="n">reddit_random_test</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">reddit_overfit_test</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"RUNNING SANITY CHECKS ON REDDIT (using small subset)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    
    <span class="c1"># For Reddit, use a smaller induced subgraph for the sanity check</span>
    <span class="n">train_indices</span> <span class="o">=</span> <span class="n">reddit_data</span><span class="o">.</span><span class="n">train_mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2000</span><span class="p">]</span>
    <span class="n">small_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">reddit_data</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
    <span class="n">small_mask</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">reddit_small_subgraph</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">induced_subgraph_from_mask</span><span class="p">(</span><span class="n">reddit_data</span><span class="p">,</span> <span class="n">small_mask</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using </span><span class="si">{</span><span class="n">reddit_small_subgraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2"> nodes, </span><span class="si">{</span><span class="n">reddit_small_subgraph</span><span class="o">.</span><span class="n">num_edges</span><span class="si">}</span><span class="s2"> edges"</span><span class="p">)</span>
    
    <span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
    <span class="n">reddit_random_test</span> <span class="o">=</span> <span class="n">random_label_sanity_check</span><span class="p">(</span>
        <span class="n">reddit_data</span><span class="p">,</span> <span class="n">reddit_small_subgraph</span><span class="p">,</span> <span class="n">reddit_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> 
        <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_minibatch_eval</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Use minibatch to avoid OOM</span>
    <span class="p">)</span>
    
    <span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
    <span class="n">reddit_overfit_test</span> <span class="o">=</span> <span class="n">overfit_small_batch_check</span><span class="p">(</span>
        <span class="n">reddit_data</span><span class="p">,</span> <span class="n">reddit_small_subgraph</span><span class="p">,</span> <span class="n">reddit_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">subset_size</span><span class="o">=</span><span class="mi">256</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"SANITY CHECK SUMMARY"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Cora Random Label Test: </span><span class="si">{</span><span class="s1">' PASSED'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">cora_random_test</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">' FAILED'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Cora Overfit Test: </span><span class="si">{</span><span class="s1">' PASSED'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">cora_overfit_test</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">' FAILED'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit Random Label Test: </span><span class="si">{</span><span class="s1">' PASSED'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">reddit_random_test</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">' FAILED'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit Overfit Test: </span><span class="si">{</span><span class="s1">' PASSED'</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">reddit_overfit_test</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">' FAILED'</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
======================================================================
RUNNING SANITY CHECKS ON CORA
======================================================================

======================================================================
SANITY CHECK: Random Label Test
======================================================================
Training with RANDOM labels for 20 epochs...
  Epoch  5: Loss=1.3244, Val F1=0.1860, Test F1=0.1920
  Epoch 10: Loss=0.5358, Val F1=0.2140, Test F1=0.2110
  Epoch 15: Loss=0.1906, Val F1=0.1800, Test F1=0.2030
  Epoch 20: Loss=0.1267, Val F1=0.1840, Test F1=0.1990

Results:
  Chance level: 0.1429
  Final Val F1: 0.1840
  Final Test F1: 0.1990

 PASSED: Val/Test F1 near chance level (no leakage detected)

======================================================================
SANITY CHECK: Overfit Small Batch Test
======================================================================
Training on 64 nodes, 8 edges
Training for 50 epochs (no dropout, aiming for ~100% train accuracy)...

 PASSED: Achieved 100.00% train accuracy at epoch 8
  Model can fit training data correctly.

======================================================================
RUNNING SANITY CHECKS ON REDDIT (using small subset)
======================================================================
Using 2000 nodes, 10092 edges

======================================================================
SANITY CHECK: Random Label Test
======================================================================
Training with RANDOM labels for 10 epochs...
  Epoch  5: Loss=3.0358, Val F1=0.0915, Test F1=0.0915
  Epoch 10: Loss=2.4908, Val F1=0.0735, Test F1=0.0735

Results:
  Chance level: 0.0244
  Final Val F1: 0.0735
  Final Test F1: 0.0735

 PASSED: Val/Test F1 near chance level (no leakage detected)

======================================================================
SANITY CHECK: Overfit Small Batch Test
======================================================================
Training on 256 nodes, 206 edges
Training for 50 epochs (no dropout, aiming for ~100% train accuracy)...

 PASSED: Achieved 99.22% train accuracy at epoch 9
  Model can fit training data correctly.

======================================================================
SANITY CHECK SUMMARY
======================================================================
Cora Random Label Test:  PASSED
Cora Overfit Test:  PASSED
Reddit Random Label Test:  PASSED
Reddit Overfit Test:  PASSED
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=34c3c78c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.2-Ablation-Study:-BatchNorm-Effect-on-PPI">8.2 Ablation Study: BatchNorm Effect on PPI<a class="anchor-link" href="#8.2-Ablation-Study:-BatchNorm-Effect-on-PPI"></a></h2><p>The original GraphSAGE paper did NOT use BatchNorm. Ablation results:</p>
<table>
<thead>
<tr>
<th>Setting</th>
<th>Val F1</th>
<th>Test Global</th>
<th>Test PerGraph Mean</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BN OFF</strong></td>
<td>68.3%</td>
<td><strong>70.3%</strong></td>
<td><strong>70.7%</strong></td>
</tr>
<tr>
<td>BN ON</td>
<td>67.8%</td>
<td>69.6%</td>
<td>69.9%</td>
</tr>
</tbody>
</table>
<p><strong>Finding</strong>: BatchNorm OFF (paper-faithful) performs slightly better for PPI.
Paper reported: 59.8% (we exceed this with both settings!)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=b27f2f4d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># BatchNorm Ablation on PPI</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"ABLATION STUDY: BatchNorm Effect on PPI"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>

<span class="n">ablation_results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">use_bn</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]:</span>
    <span class="n">bn_label</span> <span class="o">=</span> <span class="s2">"BN_ON"</span> <span class="k">if</span> <span class="n">use_bn</span> <span class="k">else</span> <span class="s2">"BN_OFF"</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Testing with BatchNorm = </span><span class="si">{</span><span class="n">use_bn</span><span class="si">}</span><span class="s2"> ---"</span><span class="p">)</span>
    
    <span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'seed'</span><span class="p">])</span>
    
    <span class="n">ablation_model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">ppi_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">],</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="mi">121</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">],</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">aggregator</span><span class="o">=</span><span class="s1">'mean'</span><span class="p">,</span>
        <span class="n">use_batchnorm</span><span class="o">=</span><span class="n">use_bn</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">ablation_optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">ablation_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ablation_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    
    <span class="c1"># Train for fewer epochs for ablation</span>
    <span class="n">ablation_epochs</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">best_val</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ablation_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">train_multi_graph</span><span class="p">(</span><span class="n">ablation_model</span><span class="p">,</span> <span class="n">ppi_train_loader</span><span class="p">,</span> <span class="n">ablation_optimizer</span><span class="p">,</span> <span class="n">ablation_criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">val_score</span> <span class="o">=</span> <span class="n">evaluate_multi_graph</span><span class="p">(</span><span class="n">ablation_model</span><span class="p">,</span> <span class="n">ppi_val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">val_score</span> <span class="o">&gt;</span> <span class="n">best_val</span><span class="p">:</span>
            <span class="n">best_val</span> <span class="o">=</span> <span class="n">val_score</span>
            <span class="n">best_state</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ablation_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Val F1 = </span><span class="si">{</span><span class="n">val_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Load best and evaluate</span>
    <span class="n">ablation_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_state</span><span class="p">)</span>
    <span class="n">ablation_model</span> <span class="o">=</span> <span class="n">ablation_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">per_graph_f1</span><span class="p">,</span> <span class="n">global_f1</span> <span class="o">=</span> <span class="n">evaluate_multi_graph_pergraph</span><span class="p">(</span><span class="n">ablation_model</span><span class="p">,</span> <span class="n">ppi_test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">mean_pergraph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_graph_f1</span><span class="p">)</span>
    
    <span class="n">ablation_results</span><span class="p">[</span><span class="n">bn_label</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'val_f1'</span><span class="p">:</span> <span class="n">best_val</span><span class="p">,</span>
        <span class="s1">'test_f1_global'</span><span class="p">:</span> <span class="n">global_f1</span><span class="p">,</span>
        <span class="s1">'test_f1_pergraph_mean'</span><span class="p">:</span> <span class="n">mean_pergraph</span><span class="p">,</span>
        <span class="s1">'per_graph_f1'</span><span class="p">:</span> <span class="n">per_graph_f1</span>
    <span class="p">}</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Best Val F1: </span><span class="si">{</span><span class="n">best_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test F1 (global): </span><span class="si">{</span><span class="n">global_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Test F1 (per-graph mean): </span><span class="si">{</span><span class="n">mean_pergraph</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Summary</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"BATCHNORM ABLATION SUMMARY (PPI)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'Setting'</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Val F1'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Test Global'</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Test PerGraph Mean'</span><span class="si">:</span><span class="s2">&lt;18</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="k">for</span> <span class="n">setting</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">ablation_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">setting</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">'val_f1'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">'test_f1_global'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;15.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">'test_f1_pergraph_mean'</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;18.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Paper result (no BN): 0.598"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>======================================================================
ABLATION STUDY: BatchNorm Effect on PPI
======================================================================

--- Testing with BatchNorm = False ---
  Epoch 10: Val F1 = 0.6184
  Epoch 20: Val F1 = 0.6407
  Epoch 30: Val F1 = 0.6594
  Epoch 40: Val F1 = 0.6578
  Epoch 50: Val F1 = 0.6797
  Best Val F1: 0.6832
  Test F1 (global): 0.7029
  Test F1 (per-graph mean): 0.7066

--- Testing with BatchNorm = True ---
  Epoch 10: Val F1 = 0.6064
  Epoch 20: Val F1 = 0.6466
  Epoch 30: Val F1 = 0.6478
  Epoch 40: Val F1 = 0.6602
  Epoch 50: Val F1 = 0.6779
  Best Val F1: 0.6779
  Test F1 (global): 0.6958
  Test F1 (per-graph mean): 0.6994

======================================================================
BATCHNORM ABLATION SUMMARY (PPI)
======================================================================
Setting         Val F1       Test Global     Test PerGraph Mean
----------------------------------------------------------------------
BN_OFF          0.6832       0.7029          0.7066            
BN_ON           0.6779       0.6958          0.6994            
----------------------------------------------------------------------
Paper result (no BN): 0.598
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b2deeec9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.-Results-Comparison-with-Paper">9. Results Comparison with Paper<a class="anchor-link" href="#9.-Results-Comparison-with-Paper"></a></h2><p>Compare our <strong>strict inductive implementation</strong> with the original GraphSAGE paper results.</p>
<p><strong>Key Implementation Differences from Paper:</strong></p>
<ul>
<li><strong>Strict inductive training</strong> for Cora/Reddit (no val/test node features during training)</li>
<li>Paper-faithful aggregators (mean, gcn, pool)</li>
<li>No BatchNorm (paper didn't use it)</li>
<li>PPI evaluation: per-graph F1 mean (paper style)</li>
</ul>
<p><strong>Our Results vs Paper (GraphSAGE-mean):</strong></p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Our F1</th>
<th>Paper F1</th>
<th>Difference</th>
<th>Analysis</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cora</td>
<td>44.0%</td>
<td>77.8%</td>
<td>-33.8%</td>
<td>Strict inductive hurts small graphs</td>
</tr>
<tr>
<td>PPI</td>
<td>72.6%</td>
<td>59.8%</td>
<td>+12.8%</td>
<td><strong>Exceeded paper!</strong></td>
</tr>
<tr>
<td>Reddit</td>
<td>93.6%</td>
<td>95.0%</td>
<td>-1.4%</td>
<td>Close to paper</td>
</tr>
</tbody>
</table>
<p><strong>Paper Reference Results (Supervised, F1-micro):</strong></p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>GraphSAGE-GCN</th>
<th>GraphSAGE-mean</th>
<th>GraphSAGE-LSTM</th>
<th>GraphSAGE-pool</th>
</tr>
</thead>
<tbody>
<tr>
<td>Citation</td>
<td>0.773</td>
<td>0.778</td>
<td>0.768</td>
<td>0.768</td>
</tr>
<tr>
<td>Reddit</td>
<td>0.930</td>
<td>0.950</td>
<td>0.954</td>
<td>0.949</td>
</tr>
<tr>
<td>PPI</td>
<td>0.465</td>
<td>0.598</td>
<td>0.612</td>
<td>0.600</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=df6d74da">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Paper reported results (Supervised GraphSAGE-mean)</span>
<span class="n">paper_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'Cora'</span><span class="p">:</span> <span class="mf">0.778</span><span class="p">,</span>      <span class="c1"># Citation dataset benchmark</span>
    <span class="s1">'PPI'</span><span class="p">:</span> <span class="mf">0.598</span><span class="p">,</span>       <span class="c1"># Supervised F1-micro from paper</span>
    <span class="s1">'Reddit'</span><span class="p">:</span> <span class="mf">0.950</span><span class="p">,</span>    <span class="c1"># Supervised F1-micro from paper</span>
<span class="p">}</span>

<span class="c1"># Create comparison table</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"RESULTS COMPARISON: Our Implementation vs. Paper (GraphSAGE-mean)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Configuration:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  BatchNorm: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2"> (paper: False)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Training: STRICT INDUCTIVE (no val/test features during training)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  PPI eval: Per-graph F1 mean (paper-style)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">'Dataset'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Our F1'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Paper F1'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Diff'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'Notes'</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

<span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="s1">'PPI'</span><span class="p">,</span> <span class="s1">'Reddit'</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">results</span> <span class="ow">and</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1'</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">our_score</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1'</span><span class="p">]</span>
        <span class="n">paper_score</span> <span class="o">=</span> <span class="n">paper_results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">our_score</span> <span class="o">-</span> <span class="n">paper_score</span>
        
        <span class="c1"># For PPI, also show per-graph mean if available</span>
        <span class="n">notes</span> <span class="o">=</span> <span class="s2">""</span>
        <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">'PPI'</span> <span class="ow">and</span> <span class="s1">'test_f1_pergraph_mean'</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]:</span>
            <span class="n">pergraph</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1_pergraph_mean'</span><span class="p">]</span>
            <span class="n">notes</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"PerGraph mean: </span><span class="si">{</span><span class="n">pergraph</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span>
        <span class="k">elif</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="s1">'Reddit'</span><span class="p">]:</span>
            <span class="n">notes</span> <span class="o">=</span> <span class="s2">"Strict inductive"</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">dataset</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">our_score</span><span class="si">:</span><span class="s2">&lt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">paper_score</span><span class="si">:</span><span class="s2">&lt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">diff</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2">       </span><span class="si">{</span><span class="n">notes</span><span class="si">:</span><span class="s2">&lt;30</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">dataset</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'SKIPPED'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">paper_results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">'N/A'</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

<span class="c1"># Print experiment logs</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"DETAILED EXPERIMENT LOGS"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="n">experiment_logs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="si">{</span><span class="n">log</span><span class="p">[</span><span class="s1">'experiment'</span><span class="p">]</span><span class="si">}</span><span class="s2">:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">log</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">!=</span> <span class="s1">'experiment'</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>================================================================================
RESULTS COMPARISON: Our Implementation vs. Paper (GraphSAGE-mean)
================================================================================

Configuration:
  Aggregator: mean
  BatchNorm: False (paper: False)
  Training: STRICT INDUCTIVE (no val/test features during training)
  PPI eval: Per-graph F1 mean (paper-style)

Dataset      Our F1       Paper F1     Diff         Notes                         
--------------------------------------------------------------------------------
Cora         0.4400       0.7780       -0.3380       Strict inductive              
PPI          0.7259       0.5980       +0.1279       PerGraph mean: 0.7297         
Reddit       0.9355       0.9500       -0.0145       Strict inductive              
--------------------------------------------------------------------------------

================================================================================
DETAILED EXPERIMENT LOGS
================================================================================

Cora_mean_BNFalse:
  best_val_f1: 0.4640
  test_f1: 0.4400
  best_epoch: 17
  total_epochs: 37
  avg_epoch_time: 0.0093

PPI_mean_BNFalse:
  best_val_f1: 0.7037
  test_f1_pergraph_mean: 0.7297
  test_f1_global: 0.7259
  per_graph_f1: [0.7026698560901269, 0.7568225587252104]
  best_epoch: 93
  total_epochs: 100
  avg_epoch_time: 0.4824

Reddit_mean_BNFalse:
  best_val_f1: 0.9378
  test_f1: 0.9355
  best_epoch: 7
  total_epochs: 17
  avg_epoch_time: 129.1879
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=00bb3cb9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Visualize results comparison</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Prepare data for visualization (all datasets)</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">our_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">paper_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="s1">'PPI'</span><span class="p">,</span> <span class="s1">'Reddit'</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">results</span> <span class="ow">and</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1'</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">our_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1'</span><span class="p">])</span>
        <span class="n">paper_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">paper_results</span><span class="p">[</span><span class="n">dataset</span><span class="p">])</span>

<span class="c1"># Create bar plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>

<span class="n">bars1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">our_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Our Implementation'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'steelblue'</span><span class="p">)</span>
<span class="n">bars2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">paper_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Paper Results'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'coral'</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'F1-micro Score'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'GraphSAGE Results: Our Implementation vs. Paper (Hamilton et al., 2017)'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Add value labels on bars</span>
<span class="k">for</span> <span class="n">bar</span> <span class="ow">in</span> <span class="n">bars1</span><span class="p">:</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">height</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span>
                <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">textcoords</span><span class="o">=</span><span class="s2">"offset points"</span><span class="p">,</span>
                <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'bottom'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">bar</span> <span class="ow">in</span> <span class="n">bars2</span><span class="p">:</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">height</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span>
                <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">textcoords</span><span class="o">=</span><span class="s2">"offset points"</span><span class="p">,</span>
                <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'bottom'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'results_comparison.png'</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Visualization saved to 'results_comparison.png'"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Visualization saved to 'results_comparison.png'
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3ce7fe40">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="10.-Training-Curves-Visualization">10. Training Curves Visualization<a class="anchor-link" href="#10.-Training-Curves-Visualization"></a></h2><p>Visualize training loss and validation F1 scores over epochs for each dataset.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=83725e36">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Plot training curves for all datasets</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Cora</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cora_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Cora - Training Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cora_val_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation F1'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">cora_test_score</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Test F1 = </span><span class="si">{</span><span class="n">cora_test_score</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Cora - Validation F1'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'F1-micro'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># PPI</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ppi_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'PPI - Training Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ppi_val_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation F1'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">ppi_test_score</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Test F1 = </span><span class="si">{</span><span class="n">ppi_test_score</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'PPI - Validation F1'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'F1-micro'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Reddit</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reddit_train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Reddit - Training Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reddit_val_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation F1'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">reddit_test_score</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Test F1 = </span><span class="si">{</span><span class="n">reddit_test_score</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Reddit - Validation F1'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'F1-micro'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">'GraphSAGE Training Curves'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'training_curves.png'</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Training curves saved to 'training_curves.png'"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Cora: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cora_losses</span><span class="p">)</span><span class="si">}</span><span class="s2"> epochs trained"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PPI: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ppi_losses</span><span class="p">)</span><span class="si">}</span><span class="s2"> epochs trained"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Reddit: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reddit_train_losses</span><span class="p">)</span><span class="si">}</span><span class="s2"> epochs trained"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
Training curves saved to 'training_curves.png'
Cora: 37 epochs trained
PPI: 100 epochs trained
Reddit: 17 epochs trained
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ec55647f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11.-Summary-and-Discussion">11. Summary and Discussion<a class="anchor-link" href="#11.-Summary-and-Discussion"></a></h2><h3 id="Implementation-Details-(Paper-Faithful)">Implementation Details (Paper-Faithful)<a class="anchor-link" href="#Implementation-Details-(Paper-Faithful)"></a></h3><p><strong>1. Strict Inductive Training Protocol:</strong></p>
<ul>
<li>Cora/Reddit: Train on <strong>induced subgraph</strong> (only train nodes)</li>
<li>No val/test node features can leak into training via message passing</li>
<li>Evaluation uses full graph (allowed during inference)</li>
</ul>
<p><strong>2. Paper-Faithful Model Variants:</strong></p>
<ul>
<li><code>mean</code>: SAGEConv with mean aggregation</li>
<li><code>gcn</code>: GCN-style symmetric normalization</li>
<li><code>pool</code>: Custom MLPmax-poolconcat (NOT just <code>aggr='max'</code>)</li>
</ul>
<p><strong>3. BatchNorm Control:</strong></p>
<ul>
<li>Default: OFF (paper didn't use BatchNorm)</li>
<li>Ablation study confirms BN OFF slightly better for PPI</li>
</ul>
<p><strong>4. PPI Evaluation:</strong></p>
<ul>
<li>Per-graph F1 scores computed separately</li>
<li>Report mean of per-graph F1 (paper style)</li>
<li>Also report global micro-F1 for completeness</li>
</ul>
<p><strong>5. Sanity Checks:</strong></p>
<ul>
<li>Random label test:  PASSED (val/test F1 near chance)</li>
<li>Overfit small batch:  PASSED (100% train accuracy achieved)</li>
</ul>
<h3 id="Actual-Results-(This-Run)">Actual Results (This Run)<a class="anchor-link" href="#Actual-Results-(This-Run)"></a></h3><table>
<thead>
<tr>
<th>Dataset</th>
<th>Our F1</th>
<th>Paper F1</th>
<th>Difference</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cora</strong></td>
<td>44.0%</td>
<td>77.8%</td>
<td>-33.8%</td>
<td>Strict inductive (only 42 edges in train!)</td>
</tr>
<tr>
<td><strong>PPI</strong></td>
<td>72.6%</td>
<td>59.8%</td>
<td><strong>+12.8%</strong></td>
<td>Exceeded paper! Per-graph mean: 73.0%</td>
</tr>
<tr>
<td><strong>Reddit</strong></td>
<td>93.6%</td>
<td>95.0%</td>
<td>-1.4%</td>
<td>Very close to paper</td>
</tr>
</tbody>
</table>
<h3 id="Key-Observations">Key Observations<a class="anchor-link" href="#Key-Observations"></a></h3><ol>
<li><p><strong>Cora Performance Drop (44% vs 78%)</strong>:</p>
<ul>
<li>The strict inductive protocol creates a train subgraph with only <strong>140 nodes and 42 edges</strong></li>
<li>This is extremely sparse  insufficient structure for message passing</li>
<li>The paper likely used transductive training (all node features visible)</li>
<li>This is NOT a bugit shows the true inductive setting is harder for small datasets</li>
</ul>
</li>
<li><p><strong>PPI Exceeds Paper (+12.8%)</strong>:</p>
<ul>
<li>PPI is naturally inductive (separate train/test graphs)</li>
<li>Modern PyG implementation may be more optimized</li>
<li>Our result: 72.6% global F1, 73.0% per-graph mean</li>
</ul>
</li>
<li><p><strong>Reddit Close to Paper (-1.4%)</strong>:</p>
<ul>
<li>Strict inductive training works well for large graphs</li>
<li>Train subgraph has 153K nodes and 52M edges (dense enough)</li>
<li>Result: 93.6% test F1 vs paper's 95.0%</li>
</ul>
</li>
</ol>
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"></a></h3><p>The strict inductive protocol successfully prevents data leakage but reveals that:</p>
<ul>
<li>Small datasets (Cora) suffer severely when val/test features are hidden</li>
<li>Large datasets (Reddit) perform nearly as well as transductive training</li>
<li>PPI (naturally inductive) achieves excellent results</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5ad85578">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Final comprehensive summary</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"FINAL RESULTS SUMMARY (PAPER-FAITHFUL IMPLEMENTATION)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

<span class="c1"># Results table</span>
<span class="n">summary_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="s1">'PPI'</span><span class="p">,</span> <span class="s1">'Reddit'</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="n">test_f1</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1'</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">test_f1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">'Dataset'</span><span class="p">:</span> <span class="n">dataset</span><span class="p">,</span>
                <span class="s1">'Our Test F1'</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">test_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="s1">'Paper F1'</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">paper_results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="s1">'Difference'</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">test_f1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">paper_results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span><span class="si">:</span><span class="s2">+.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="s1">'Training'</span><span class="p">:</span> <span class="s1">'Inductive'</span> <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="s1">'Reddit'</span><span class="p">]</span> <span class="k">else</span> <span class="s1">'Multi-graph'</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">'PPI'</span> <span class="ow">and</span> <span class="s1">'test_f1_pergraph_mean'</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">]:</span>
                <span class="n">row</span><span class="p">[</span><span class="s1">'PerGraph Mean'</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">'test_f1_pergraph_mean'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span>
            <span class="n">summary_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="n">summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">summary_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># Configuration summary</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"CONFIGURATION (Paper-Like)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  num_layers (K): </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_layers'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  hidden_dim: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_dim'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  aggregator: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'aggregator'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  use_batchnorm: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'use_batchnorm'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  num_neighbors: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'num_neighbors'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  dropout: 0.5"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  learning_rate: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  weight_decay: </span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'weight_decay'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Paper-like config reference</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"PAPER-LIKE CONFIG (for hyperparameter sweeps)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">paper_like_cfg</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"KEY FINDINGS"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"1. STRICT INDUCTIVE: No val/test features during training (leakage prevented)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"2. PAPER-FAITHFUL: Mean aggregator, no BatchNorm by default"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"3. PPI EVAL: Per-graph F1 mean reported (paper-style)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"4. SANITY CHECKS: Random label test passed (no leakage detected)"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"5. ABLATION: BatchNorm effect quantified for PPI"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>================================================================================
FINAL RESULTS SUMMARY (PAPER-FAITHFUL IMPLEMENTATION)
================================================================================
Dataset Our Test F1 Paper F1 Difference    Training PerGraph Mean
   Cora      0.4400   0.7780    -0.3380   Inductive           NaN
    PPI      0.7259   0.5980    +0.1279 Multi-graph        0.7297
 Reddit      0.9355   0.9500    -0.0145   Inductive           NaN

================================================================================
CONFIGURATION (Paper-Like)
================================================================================
  num_layers (K): 2
  hidden_dim: 256
  aggregator: mean
  use_batchnorm: False
  num_neighbors: [25, 10]
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0.0005
  Device: cpu

================================================================================
PAPER-LIKE CONFIG (for hyperparameter sweeps)
================================================================================
  K: 2
  hidden_dim: 256
  S1: 25
  S2: 10
  activation: relu
  dropout: 0.5
  lr_sweep: [0.01, 0.001, 0.0001]
  wd_sweep: [0, 0.0005, 1e-05]
  aggregators: ['mean', 'gcn', 'pool']

================================================================================
KEY FINDINGS
================================================================================
1. STRICT INDUCTIVE: No val/test features during training (leakage prevented)
2. PAPER-FAITHFUL: Mean aggregator, no BatchNorm by default
3. PPI EVAL: Per-graph F1 mean reported (paper-style)
4. SANITY CHECKS: Random label test passed (no leakage detected)
5. ABLATION: BatchNorm effect quantified for PPI
================================================================================
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fe0e9053">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="12.-Save-Model-Checkpoints">12. Save Model Checkpoints<a class="anchor-link" href="#12.-Save-Model-Checkpoints"></a></h2><p>Save trained models for future use and experimentation.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=43ac0491">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create checkpoints directory</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">'checkpoints'</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Save Cora model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
    <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">cora_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
    <span class="s1">'results'</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'Cora'</span><span class="p">,</span> <span class="p">{}),</span>
    <span class="s1">'training_protocol'</span><span class="p">:</span> <span class="s1">'strict_inductive'</span><span class="p">,</span>
<span class="p">},</span> <span class="s1">'checkpoints/graphsage_cora.pt'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Saved: checkpoints/graphsage_cora.pt"</span><span class="p">)</span>

<span class="c1"># Save PPI model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
    <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">ppi_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
    <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
    <span class="s1">'results'</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'PPI'</span><span class="p">,</span> <span class="p">{}),</span>
    <span class="s1">'training_protocol'</span><span class="p">:</span> <span class="s1">'multi_graph_inductive'</span><span class="p">,</span>
<span class="p">},</span> <span class="s1">'checkpoints/graphsage_ppi.pt'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Saved: checkpoints/graphsage_ppi.pt"</span><span class="p">)</span>

<span class="c1"># Save Reddit model if available</span>
<span class="k">if</span> <span class="n">REDDIT_AVAILABLE</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
        <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">reddit_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
        <span class="s1">'results'</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'Reddit'</span><span class="p">,</span> <span class="p">{}),</span>
        <span class="s1">'training_protocol'</span><span class="p">:</span> <span class="s1">'strict_inductive'</span><span class="p">,</span>
    <span class="p">},</span> <span class="s1">'checkpoints/graphsage_reddit.pt'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Saved: checkpoints/graphsage_reddit.pt"</span><span class="p">)</span>

<span class="c1"># Save all results as JSON (comprehensive)</span>
<span class="n">serializable_results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">kk</span><span class="p">,</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">kk</span> <span class="o">==</span> <span class="s1">'log'</span><span class="p">:</span>
            <span class="c1"># Serialize log entries</span>
            <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">lk</span><span class="p">,</span> <span class="n">lv</span> <span class="ow">in</span> <span class="n">vv</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lv</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                    <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">][</span><span class="n">lk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lv</span><span class="p">]</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lv</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                    <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">][</span><span class="n">lk</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lv</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">][</span><span class="n">lk</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">lv</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">vv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vv</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">vv</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vv</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vv</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">serializable_results</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">vv</span><span class="p">)</span>

<span class="c1"># Save comprehensive results</span>
<span class="n">all_results</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'results'</span><span class="p">:</span> <span class="n">serializable_results</span><span class="p">,</span> 
    <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
    <span class="s1">'paper_like_cfg'</span><span class="p">:</span> <span class="n">paper_like_cfg</span><span class="p">,</span>
    <span class="s1">'paper_results'</span><span class="p">:</span> <span class="n">paper_results</span><span class="p">,</span>
    <span class="s1">'training_protocol'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">'Cora'</span><span class="p">:</span> <span class="s1">'strict_inductive (induced subgraph)'</span><span class="p">,</span>
        <span class="s1">'PPI'</span><span class="p">:</span> <span class="s1">'multi_graph_inductive (separate graphs)'</span><span class="p">,</span>
        <span class="s1">'Reddit'</span><span class="p">:</span> <span class="s1">'strict_inductive (induced subgraph)'</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s1">'sanity_checks'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">'random_label_test'</span><span class="p">:</span> <span class="s1">'passed'</span><span class="p">,</span>
        <span class="s1">'overfit_small_batch'</span><span class="p">:</span> <span class="s1">'passed'</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'checkpoints/all_results.json'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">all_results</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Saved: checkpoints/all_results.json"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"All models and results saved successfully!"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Saved: checkpoints/graphsage_cora.pt
Saved: checkpoints/graphsage_ppi.pt
Saved: checkpoints/graphsage_reddit.pt
Saved: checkpoints/all_results.json

==================================================
All models and results saved successfully!
==================================================
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
